{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a28bac6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acro0/NLP/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline: ['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from spacy import displacy\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "print(\"Pipeline:\", nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958c1530",
   "metadata": {},
   "source": [
    "# Part-of-speech tagging\n",
    "\n",
    "    Text: The original word text.\n",
    "    \n",
    "    Lemma: The base form of the word.\n",
    "    \n",
    "    POS: The simple UPOS part-of-speech tag.\n",
    "    \n",
    "    Tag: The detailed part-of-speech tag.\n",
    "    \n",
    "    Dep: Syntactic dependency, i.e. the relation between tokens.\n",
    "    \n",
    "    Shape: The word shape – capitalization, punctuation, digits.\n",
    "    \n",
    "    is alpha: Is the token an alpha character?\n",
    "    \n",
    "    is stop: Is the token part of a stop list (most common words)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1da9adb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Dep</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Is_Alpha</th>\n",
       "      <th>Is_Stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple</td>\n",
       "      <td>Apple</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>aux</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>looking</td>\n",
       "      <td>look</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBG</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>at</td>\n",
       "      <td>at</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>prep</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>buying</td>\n",
       "      <td>buy</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBG</td>\n",
       "      <td>pcomp</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>U.K.</td>\n",
       "      <td>U.K.</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>dobj</td>\n",
       "      <td>X.X.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>startup</td>\n",
       "      <td>startup</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>dep</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>for</td>\n",
       "      <td>for</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>prep</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>$</td>\n",
       "      <td>$</td>\n",
       "      <td>SYM</td>\n",
       "      <td>$</td>\n",
       "      <td>quantmod</td>\n",
       "      <td>$</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NUM</td>\n",
       "      <td>CD</td>\n",
       "      <td>compound</td>\n",
       "      <td>d</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>billion</td>\n",
       "      <td>billion</td>\n",
       "      <td>NUM</td>\n",
       "      <td>CD</td>\n",
       "      <td>pobj</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Text    Lemma    POS  Tag       Dep  Shape  Is_Alpha  Is_Stop\n",
       "0     Apple    Apple  PROPN  NNP     nsubj  Xxxxx      True    False\n",
       "1        is       be    AUX  VBZ       aux     xx      True     True\n",
       "2   looking     look   VERB  VBG      ROOT   xxxx      True    False\n",
       "3        at       at    ADP   IN      prep     xx      True     True\n",
       "4    buying      buy   VERB  VBG     pcomp   xxxx      True    False\n",
       "5      U.K.     U.K.  PROPN  NNP      dobj   X.X.     False    False\n",
       "6   startup  startup   NOUN   NN       dep   xxxx      True    False\n",
       "7       for      for    ADP   IN      prep    xxx      True     True\n",
       "8         $        $    SYM    $  quantmod      $     False    False\n",
       "9         1        1    NUM   CD  compound      d     False    False\n",
       "10  billion  billion    NUM   CD      pobj   xxxx      True    False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "\n",
    "data = []\n",
    "column_names = [\"Text\",\"Lemma\", \"POS\", \"Tag\", \"Dep\",\"Shape\",\"Is_Alpha\",\"Is_Stop\"]\n",
    "\n",
    "for token in doc:\n",
    "    data.append([token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop])\n",
    "    \n",
    "df = pd.DataFrame(data, columns=column_names)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "85e55ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"d09077c0ef984755a63a41c3d8f9467d-0\" class=\"displacy\" width=\"1040\" height=\"272.0\" direction=\"ltr\" style=\"max-width: none; height: 272.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Apple</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"140\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"140\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"230\">looking</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"230\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"320\">at</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"320\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">buying</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">U.K.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"590\">startup</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"590\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"680\">for</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"680\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">$</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">SYM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"860\">1</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"860\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">billion</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d09077c0ef984755a63a41c3d8f9467d-0-0\" stroke-width=\"2px\" d=\"M70,137.0 C70,47.0 225.0,47.0 225.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d09077c0ef984755a63a41c3d8f9467d-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,139.0 L62,127.0 78,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d09077c0ef984755a63a41c3d8f9467d-0-1\" stroke-width=\"2px\" d=\"M160,137.0 C160,92.0 220.0,92.0 220.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d09077c0ef984755a63a41c3d8f9467d-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M160,139.0 L152,127.0 168,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d09077c0ef984755a63a41c3d8f9467d-0-2\" stroke-width=\"2px\" d=\"M250,137.0 C250,92.0 310.0,92.0 310.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d09077c0ef984755a63a41c3d8f9467d-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M310.0,139.0 L318.0,127.0 302.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d09077c0ef984755a63a41c3d8f9467d-0-3\" stroke-width=\"2px\" d=\"M340,137.0 C340,92.0 400.0,92.0 400.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d09077c0ef984755a63a41c3d8f9467d-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M400.0,139.0 L408.0,127.0 392.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d09077c0ef984755a63a41c3d8f9467d-0-4\" stroke-width=\"2px\" d=\"M430,137.0 C430,92.0 490.0,92.0 490.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d09077c0ef984755a63a41c3d8f9467d-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M490.0,139.0 L498.0,127.0 482.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d09077c0ef984755a63a41c3d8f9467d-0-5\" stroke-width=\"2px\" d=\"M250,137.0 C250,47.0 585.0,47.0 585.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d09077c0ef984755a63a41c3d8f9467d-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M585.0,139.0 L593.0,127.0 577.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d09077c0ef984755a63a41c3d8f9467d-0-6\" stroke-width=\"2px\" d=\"M610,137.0 C610,92.0 670.0,92.0 670.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d09077c0ef984755a63a41c3d8f9467d-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M670.0,139.0 L678.0,127.0 662.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d09077c0ef984755a63a41c3d8f9467d-0-7\" stroke-width=\"2px\" d=\"M790,137.0 C790,47.0 945.0,47.0 945.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d09077c0ef984755a63a41c3d8f9467d-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">quantmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M790,139.0 L782,127.0 798,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d09077c0ef984755a63a41c3d8f9467d-0-8\" stroke-width=\"2px\" d=\"M880,137.0 C880,92.0 940.0,92.0 940.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d09077c0ef984755a63a41c3d8f9467d-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M880,139.0 L872,127.0 888,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-d09077c0ef984755a63a41c3d8f9467d-0-9\" stroke-width=\"2px\" d=\"M700,137.0 C700,2.0 950.0,2.0 950.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-d09077c0ef984755a63a41c3d8f9467d-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M950.0,139.0 L958.0,127.0 942.0,127.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style='dep', jupyter=True, options={'distance': 90})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "987e0043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is looking at buying \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    U.K.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " startup for \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $1 billion\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style='ent', jupyter=True, options={'distance': 30})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46194c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acro0/NLP/lib/python3.11/site-packages/spacy/displacy/__init__.py:244: UserWarning: [W117] No spans to visualize found in Doc object with spans_key: 'sc'. If this is surprising to you, make sure the Doc was processed using a model that supports span categorization, and check the `doc.spans[spans_key]` property manually if necessary.\n",
      "\n",
      "Available keys: []\n",
      "  warnings.warn(Warnings.W117.format(spans_key=spans_key, keys=keys))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"spans\" style=\"line-height: 2.5; direction: ltr\">Apple is looking at buying U.K. startup for $ 1 billion </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style='span', jupyter=True, options={'distance': 30})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ff0ed4",
   "metadata": {},
   "source": [
    "# Morphology\n",
    "\n",
    "We say that a lemma (root form) is inflected (modified/combined) with one or more morphological features to create a surface form\n",
    "\n",
    "\n",
    "\n",
    "| CONTEXT                |\tSURFACE\t | LEMMA  | POS   | MORPHOLOGICAL FEATURES |\n",
    "|------------------------|-----------|--------|-------|------------------------|\n",
    "|I was reading the paper | reading   |\tread  |\tVERB  |\tVerbForm=Ger           |\n",
    "|------------------------------------------------------------------------------|\n",
    "|I don’t watch the news, |   read    |  read  | VERB  | VerbForm=Fin,          |\n",
    "|I read the paper \t     |\t    \t |        |\t      | Mood=Ind, Tense=Pres   |\n",
    "|------------------------------------------------------------------------------|\n",
    "|I read the paper        |   read    |   read | VERB  | VerbForm=Fin,          |\n",
    "|yesterday\t             |      \t |   \t  |       |\tMood=Ind,Tense=Past    |\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c992e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Case': 'Nom', 'Number': 'Sing', 'Person': '1', 'PronType': 'Prs'}\n",
      "['Prs']\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"I was reading the paper.\")\n",
    "token = doc[0]  # 'I'\n",
    "print(token.morph.to_dict())  # 'Case=Nom|Number=Sing|Person=1|PronType=Prs'\n",
    "print(token.morph.get(\"PronType\"))  # ['Prs']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dde6145",
   "metadata": {},
   "source": [
    "## Statistical morphology \n",
    "\n",
    "spaCy’s statistical Morphologizer component assigns the morphological features and coarse-grained part-of-speech tags as Token.morph and Token.pos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fed1ee89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number=Sing\n",
      "PROPN\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Wo bist du?\") # English: 'Where are you?'\n",
    "print(doc[2].morph)  # 'Case=Nom|Number=Sing|Person=2|PronType=Prs'\n",
    "print(doc[2].pos_) # 'PRON'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f9fe20",
   "metadata": {},
   "source": [
    "## Rule-based morphology\n",
    "\n",
    "For languages with relatively simple morphological systems like English, spaCy can assign morphological features through a rule-based approach, which uses the token text and fine-grained part-of-speech tags to produce coarse-grained part-of-speech tags and morphological features.\n",
    "\n",
    "The part-of-speech tagger assigns each token a fine-grained part-of-speech tag. In the API, these tags are known as Token.tag. They express the part-of-speech (e.g. verb) and some amount of morphological information, e.g. that the verb is past tense (e.g. VBD for a past tense verb in the Penn Treebank) .\n",
    "For words whose coarse-grained POS is not set by a prior process, a mapping table maps the fine-grained tags to a coarse-grained POS tags and morphological features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36c63402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case=Nom|Person=2|PronType=Prs\n",
      "PRON\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Where are you?\")\n",
    "print(doc[2].morph)  # 'Case=Nom|Person=2|PronType=Prs'\n",
    "print(doc[2].pos_)  # 'PRON'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b18b989-85f8-450e-92d0-75da00062638",
   "metadata": {},
   "source": [
    "# Lemmatization\n",
    "\n",
    "The EditTreeLemmatizer component provides a trainable lemmatizer.\n",
    "\n",
    "\n",
    "### Rule Based Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a49ebfce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemmatization mode :  rule\n",
      "['I', 'be', 'read', 'the', 'paper', '.']\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = nlp.get_pipe(\"lemmatizer\")\n",
    "print(\"lemmatization mode : \",lemmatizer.mode)  # 'rule'\n",
    "\n",
    "doc = nlp(\"I was reading the paper.\")\n",
    "print([token.lemma_ for token in doc])\n",
    "# ['I', 'be', 'read', 'the', 'paper', '.']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb64c66-19fc-454c-b7b1-6d46ec850e62",
   "metadata": {},
   "source": [
    "## Lookup lemmatizer\n",
    "\n",
    "For pipelines without a tagger or morphologizer, a lookup lemmatizer can be added to the pipeline as long as a lookup table is provided, typically through spacy-lookups-data. The lookup lemmatizer looks up the token surface form in the lookup table without reference to the token’s part-of-speech or context.\n",
    "\n",
    "\n",
    "\n",
    "            # pip install -U spacy[lookups]\n",
    "            import spacy\n",
    "            \n",
    "            nlp = spacy.blank(\"sv\")\n",
    "            nlp.add_pipe(\"lemmatizer\", config={\"mode\": \"lookup\"})\n",
    "\n",
    " ## Rule-based lemmatizer\n",
    "\n",
    "When training pipelines that include a component that assigns part-of-speech tags (a morphologizer or a tagger with a POS mapping), a rule-based lemmatizer can be added using rule tables from spacy-lookups-data\n",
    "\n",
    "            # pip install -U spacy[lookups]\n",
    "            import spacy\n",
    "            \n",
    "            nlp = spacy.blank(\"de\")\n",
    "            # Morphologizer (note: model is not yet trained!)\n",
    "            nlp.add_pipe(\"morphologizer\")\n",
    "            # Rule-based lemmatizer\n",
    "            nlp.add_pipe(\"lemmatizer\", config={\"mode\": \"rule\"})\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6f9e87-0be1-42c0-b5eb-eb443767dc60",
   "metadata": {},
   "source": [
    "# Dependency Parsing\n",
    "\n",
    "he parser also powers the sentence boundary detection, and lets you iterate over base noun phrases, or “chunks”.\n",
    "\n",
    "### Noun chunks\n",
    "\n",
    "Noun chunks are “base noun phrases” – flat phrases that have a noun as their head. You can think of noun chunks as a noun plus the words describing the noun – for example, “the lavish green grass” or “the world’s largest tech fund”. \n",
    "\n",
    "        Text: The original noun chunk text.\n",
    "        \n",
    "        Root text: The original text of the word connecting the noun chunk to the rest of the parse.\n",
    "        \n",
    "        Root dep: Dependency relation connecting the root to its head.\n",
    "            \n",
    "        Root head text: The text of the root token’s head.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "781689b4-eea4-4f0b-84b3-057bee40b8a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Root_Text</th>\n",
       "      <th>Root_Dep</th>\n",
       "      <th>Root_head_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autonomous cars</td>\n",
       "      <td>cars</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>shift</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>insurance liability</td>\n",
       "      <td>liability</td>\n",
       "      <td>dobj</td>\n",
       "      <td>shift</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>manufacturers</td>\n",
       "      <td>manufacturers</td>\n",
       "      <td>pobj</td>\n",
       "      <td>toward</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Text      Root_Text Root_Dep Root_head_text\n",
       "0      Autonomous cars           cars    nsubj          shift\n",
       "1  insurance liability      liability     dobj          shift\n",
       "2        manufacturers  manufacturers     pobj         toward"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"Autonomous cars shift insurance liability toward manufacturers\")\n",
    "data = []\n",
    "for chunk in doc.noun_chunks:\n",
    "    data.append([chunk.text, chunk.root.text, chunk.root.dep_,chunk.root.head.text])\n",
    "\n",
    "df = pd.DataFrame(data,columns=[\"Text\",\"Root_Text\",\"Root_Dep\",\"Root_head_text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bc4379-6970-48b4-aa74-457ae1b5086d",
   "metadata": {},
   "source": [
    "## Navigating the parse tree\n",
    "\n",
    "spaCy uses the terms head and child to describe the words connected by a single arc in the dependency tree. The term dep is used for the arc label, which describes the type of syntactic relation that connects the child to the head. As with other attributes, the value of .dep is a hash value. You can get the string value with .dep_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f5825f0-362d-44e7-b653-02ff7739da40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Dep</th>\n",
       "      <th>Head_Text</th>\n",
       "      <th>Head_Pos</th>\n",
       "      <th>Children</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autonomous</td>\n",
       "      <td>amod</td>\n",
       "      <td>cars</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cars</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>shift</td>\n",
       "      <td>VERB</td>\n",
       "      <td>[Autonomous]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shift</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>shift</td>\n",
       "      <td>VERB</td>\n",
       "      <td>[cars, liability, toward]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>insurance</td>\n",
       "      <td>compound</td>\n",
       "      <td>liability</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>liability</td>\n",
       "      <td>dobj</td>\n",
       "      <td>shift</td>\n",
       "      <td>VERB</td>\n",
       "      <td>[insurance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>toward</td>\n",
       "      <td>prep</td>\n",
       "      <td>shift</td>\n",
       "      <td>VERB</td>\n",
       "      <td>[manufacturers]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>manufacturers</td>\n",
       "      <td>pobj</td>\n",
       "      <td>toward</td>\n",
       "      <td>ADP</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Text       Dep  Head_Text Head_Pos                   Children\n",
       "0     Autonomous      amod       cars     NOUN                         []\n",
       "1           cars     nsubj      shift     VERB               [Autonomous]\n",
       "2          shift      ROOT      shift     VERB  [cars, liability, toward]\n",
       "3      insurance  compound  liability     NOUN                         []\n",
       "4      liability      dobj      shift     VERB                [insurance]\n",
       "5         toward      prep      shift     VERB            [manufacturers]\n",
       "6  manufacturers      pobj     toward      ADP                         []"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"Autonomous cars shift insurance liability toward manufacturers\")\n",
    "data = []\n",
    "for token in doc:\n",
    "    data.append([token.text, token.dep_, token.head.text, token.head.pos_,\n",
    "            [child for child in token.children]])\n",
    "\n",
    "df = pd.DataFrame(data,columns=[\"Text\",\"Dep\",\"Head_Text\",\"Head_Pos\",\"Children\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a1c9cb9-cff4-453e-bcfe-3a7f5e662ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"e934a3f84f5c48c7b8e4e0a292c33d56-0\" class=\"displacy\" width=\"750\" height=\"287.0\" direction=\"ltr\" style=\"max-width: none; height: 287.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Autonomous</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"150\">cars</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"150\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"250\">shift</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"250\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">insurance</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"450\">liability</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"450\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"550\">toward</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"550\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">manufacturers</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e934a3f84f5c48c7b8e4e0a292c33d56-0-0\" stroke-width=\"2px\" d=\"M70,152.0 C70,102.0 140.0,102.0 140.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e934a3f84f5c48c7b8e4e0a292c33d56-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,154.0 L62,142.0 78,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e934a3f84f5c48c7b8e4e0a292c33d56-0-1\" stroke-width=\"2px\" d=\"M170,152.0 C170,102.0 240.0,102.0 240.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e934a3f84f5c48c7b8e4e0a292c33d56-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M170,154.0 L162,142.0 178,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e934a3f84f5c48c7b8e4e0a292c33d56-0-2\" stroke-width=\"2px\" d=\"M370,152.0 C370,102.0 440.0,102.0 440.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e934a3f84f5c48c7b8e4e0a292c33d56-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M370,154.0 L362,142.0 378,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e934a3f84f5c48c7b8e4e0a292c33d56-0-3\" stroke-width=\"2px\" d=\"M270,152.0 C270,52.0 445.0,52.0 445.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e934a3f84f5c48c7b8e4e0a292c33d56-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M445.0,154.0 L453.0,142.0 437.0,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e934a3f84f5c48c7b8e4e0a292c33d56-0-4\" stroke-width=\"2px\" d=\"M270,152.0 C270,2.0 550.0,2.0 550.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e934a3f84f5c48c7b8e4e0a292c33d56-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M550.0,154.0 L558.0,142.0 542.0,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e934a3f84f5c48c7b8e4e0a292c33d56-0-5\" stroke-width=\"2px\" d=\"M570,152.0 C570,102.0 640.0,102.0 640.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e934a3f84f5c48c7b8e4e0a292c33d56-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M640.0,154.0 L648.0,142.0 632.0,142.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style='dep', jupyter=True, options={'distance': 100})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae7985b-da93-40de-bb3c-bf12e9b225e6",
   "metadata": {},
   "source": [
    "# Named Entity Recognition\n",
    "\n",
    "    Text: The original entity text.\n",
    "    \n",
    "    Start: Index of start of entity in the Doc.\n",
    "    \n",
    "    End: Index of end of entity in the Doc.\n",
    "    \n",
    "    Label: Entity label, i.e. type.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1b8f61e2-0f53-47ac-a2d2-97952368ad6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Start_char</th>\n",
       "      <th>End_char</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.K.</td>\n",
       "      <td>27</td>\n",
       "      <td>31</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$1 billion</td>\n",
       "      <td>44</td>\n",
       "      <td>54</td>\n",
       "      <td>MONEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sebastian Thrun</td>\n",
       "      <td>61</td>\n",
       "      <td>76</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Google</td>\n",
       "      <td>117</td>\n",
       "      <td>123</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2007</td>\n",
       "      <td>127</td>\n",
       "      <td>131</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Text  Start_char  End_char   Label\n",
       "0            Apple           0         5     ORG\n",
       "1             U.K.          27        31     GPE\n",
       "2       $1 billion          44        54   MONEY\n",
       "3  Sebastian Thrun          61        76  PERSON\n",
       "4           Google         117       123     ORG\n",
       "5             2007         127       131    DATE"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion. When Sebastian Thrun started working on self-driving cars at Google in 2007, few people outside of the company took him seriously.\")\n",
    "data = []\n",
    "for ent in doc.ents:\n",
    "    data.append([ent.text, ent.start_char, ent.end_char, ent.label_])\n",
    "\n",
    "df = pd.DataFrame(data,columns=[\"Text\",\"Start_char\",\"End_char\",\"Label\"])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cdc099fc-a342-4edd-a874-5cc3ea8e0343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is looking at buying \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    U.K.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " startup for \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $1 billion\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       ". When \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sebastian Thrun\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " started working on self-driving cars at \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Google\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2007\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", few people outside of the company took him seriously.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style='ent', jupyter=True, options={'distance': 100})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ba70c5-abb0-40b1-a35f-394b4db3a2ae",
   "metadata": {},
   "source": [
    "## Entity Linking\n",
    "\n",
    "To ground the named entities into the “real world”, spaCy provides functionality to perform entity linking, which resolves a textual entity to a unique identifier from a knowledge base (KB). You can create your own KnowledgeBase and train a new EntityLinker using that custom knowledge base.\n",
    "\n",
    "Accessing entity identifiers NEEDS MODEL\n",
    "The annotated KB identifier is accessible as either a hash value or as a string, using the attributes ent.kb_id and ent.kb_id_ of a Span object, or the ent_kb_id and ent_kb_id_ attributes of a Token object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b5981855-caa9-4742-87a9-e49ff8b17888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Ada Lovelace', 'PERSON', ''), ('London', 'GPE', '')]\n",
      "['Ada', 'PERSON', '']\n",
      "['Lovelace', 'PERSON', '']\n",
      "['London', 'GPE', '']\n"
     ]
    }
   ],
   "source": [
    "# nlp = spacy.load(\"my_custom_el_pipeline\")\n",
    "\n",
    "doc = nlp(\"Ada Lovelace was born in London\")\n",
    "\n",
    "# Document level\n",
    "ents = [(e.text, e.label_, e.kb_id_) for e in doc.ents]\n",
    "print(ents)  # [('Ada Lovelace', 'PERSON', 'Q7259'), ('London', 'GPE', 'Q84')]\n",
    "\n",
    "# Token level\n",
    "ent_ada_0 = [doc[0].text, doc[0].ent_type_, doc[0].ent_kb_id_]\n",
    "ent_ada_1 = [doc[1].text, doc[1].ent_type_, doc[1].ent_kb_id_]\n",
    "ent_london_5 = [doc[5].text, doc[5].ent_type_, doc[5].ent_kb_id_]\n",
    "print(ent_ada_0)  # ['Ada', 'PERSON', 'Q7259']\n",
    "print(ent_ada_1)  # ['Lovelace', 'PERSON', 'Q7259']\n",
    "print(ent_london_5)  # ['London', 'GPE', 'Q84']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99898186-3cdb-4676-b4ed-5d3ebefc7115",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "\n",
    "Tokenizer exception: Special-case rule to split a string into several tokens or prevent a token from being split when punctuation rules are applied.\n",
    "\n",
    "    Prefix: Character(s) at the beginning, e.g. $, (, “, ¿.\n",
    "    \n",
    "    Suffix: Character(s) at the end, e.g. km, ), ”, !.\n",
    "    \n",
    "    Infix: Character(s) in between, e.g. -, --, /, …."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cd8bad0f-3bcf-44c3-8ed9-752b2eadf611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gimme', 'that']\n",
      "['gim', 'me', 'that']\n"
     ]
    }
   ],
   "source": [
    "from spacy.symbols import ORTH\n",
    "\n",
    "\n",
    "doc = nlp(\"gimme that\")  # phrase to tokenize\n",
    "print([w.text for w in doc])  # ['gimme', 'that']\n",
    "\n",
    "# Add special case rule\n",
    "special_case = [{ORTH: \"gim\"}, {ORTH: \"me\"}]\n",
    "nlp.tokenizer.add_special_case(\"gimme\", special_case)\n",
    "\n",
    "# Check new tokenization\n",
    "print([w.text for w in nlp(\"gimme that\")])  # ['gim', 'me', 'that']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e0cb6dc4-9c5c-45eb-9ca4-2dae5a238682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>looking</td>\n",
       "      <td>looking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>at</td>\n",
       "      <td>at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>buying</td>\n",
       "      <td>buying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>U.K.</td>\n",
       "      <td>U.K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>startup</td>\n",
       "      <td>startup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>for</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>$1</td>\n",
       "      <td>$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>billion</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>None</td>\n",
       "      <td>billion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Text   Tokens\n",
       "0     Apple    Apple\n",
       "1        is       is\n",
       "2   looking  looking\n",
       "3        at       at\n",
       "4    buying   buying\n",
       "5      U.K.     U.K.\n",
       "6   startup  startup\n",
       "7       for      for\n",
       "8        $1        $\n",
       "9   billion        1\n",
       "10     None  billion"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "text = \"Apple is looking at buying U.K. startup for $1 billion\"\n",
    "orginal = text.split()\n",
    "doc = nlp(text)\n",
    "\n",
    "data = []\n",
    "for token in doc:\n",
    "    data.append(token.text)\n",
    "    \n",
    "nested = [orginal,data]\n",
    "df = pd.DataFrame((_ for _ in itertools.zip_longest(*nested)), columns=[\"Text\",\"Tokens\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bda10f01-9e2a-45fe-b071-4418b3ced6d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apple',\n",
       " 'is',\n",
       " 'looking',\n",
       " 'at',\n",
       " 'buying',\n",
       " 'U.K.',\n",
       " 'startup',\n",
       " 'for',\n",
       " '$',\n",
       " '1',\n",
       " 'billion']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75561d7-e4dd-4229-8c2a-cb76d944dfe1",
   "metadata": {},
   "source": [
    "## Debugging the tokenizer\n",
    "A working implementation of the pseudo-code above is available for debugging as nlp.tokenizer.explain(text). It returns a list of tuples showing which tokenizer rule or pattern was matched for each token. The tokens produced are identical to nlp.tokenizer() except for whitespace tokens:\n",
    "\n",
    "    \"      PREFIX\n",
    "    Let    SPECIAL-1\n",
    "    's     SPECIAL-2\n",
    "    go     TOKEN\n",
    "    !      SUFFIX\n",
    "    \"      SUFFIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d98ed98d-8590-482b-9ece-9b5e88b2b01c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"</td>\n",
       "      <td>PREFIX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Let</td>\n",
       "      <td>SPECIAL-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'s</td>\n",
       "      <td>SPECIAL-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>go</td>\n",
       "      <td>TOKEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>!</td>\n",
       "      <td>SUFFIX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"</td>\n",
       "      <td>SUFFIX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Tokens     Labels\n",
       "0      \"     PREFIX\n",
       "1    Let  SPECIAL-1\n",
       "2     's  SPECIAL-2\n",
       "3     go      TOKEN\n",
       "4      !     SUFFIX\n",
       "5      \"     SUFFIX"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.lang.en import English\n",
    "\n",
    "nlp = English()\n",
    "text = '''\"Let's go!\"'''\n",
    "doc = nlp(text)\n",
    "tok_exp = nlp.tokenizer.explain(text)\n",
    "assert [t.text for t in doc if not t.is_space] == [t[1] for t in tok_exp]\n",
    "df = pd.DataFrame(columns=[\"Tokens\",\"Labels\"])\n",
    "for idx,t in enumerate(tok_exp):\n",
    "    df.loc[idx]=[t[1],t[0]]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb272a42-c1d4-4704-8640-d49bda49005f",
   "metadata": {},
   "source": [
    "## Modifying existing rule sets\n",
    "\n",
    "If you need to subclass the tokenizer instead, the relevant methods to specialize are find_prefix, find_suffix and find_infix.\n",
    "\n",
    "\n",
    "In many situations, you don’t necessarily need entirely custom rules. Sometimes you just want to add another character to the prefixes, suffixes or infixes. The default prefix, suffix and infix rules are available via the nlp object’s Defaults and the Tokenizer attributes such as Tokenizer.suffix_search are writable, so you can overwrite them with compiled regular expression objects using modified default rules. spaCy ships with utility functions to help you compile the regular expressions – for example,\n",
    "\n",
    "The prefix, infix and suffix rule sets include not only individual characters but also detailed regular expressions that take the surrounding context into account. For example, there is a regular expression that treats a hyphen between letters as an infix. If you do not want the tokenizer to split on hyphens between letters, you can modify the existing infix definition from lang/punctuation.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a91f111e-ab70-4bb7-8a28-39e639e916da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mother', '-', 'in', '-', 'law']\n",
      "['mother-in-law']\n"
     ]
    }
   ],
   "source": [
    "from spacy.lang.char_classes import ALPHA, ALPHA_LOWER, ALPHA_UPPER\n",
    "from spacy.lang.char_classes import CONCAT_QUOTES, LIST_ELLIPSES, LIST_ICONS\n",
    "from spacy.util import compile_infix_regex\n",
    "\n",
    "# Default tokenizer\n",
    "doc = nlp(\"mother-in-law\")\n",
    "print([t.text for t in doc]) # ['mother', '-', 'in', '-', 'law']\n",
    "\n",
    "# Modify tokenizer infix patterns\n",
    "infixes = (\n",
    "    LIST_ELLIPSES\n",
    "    + LIST_ICONS\n",
    "    + [\n",
    "        r\"(?<=[0-9])[+\\\\-\\\\*^](?=[0-9-])\",\n",
    "        r\"(?<=[{al}{q}])\\\\.(?=[{au}{q}])\".format(\n",
    "            al=ALPHA_LOWER, au=ALPHA_UPPER, q=CONCAT_QUOTES\n",
    "        ),\n",
    "        r\"(?<=[{a}]),(?=[{a}])\".format(a=ALPHA),\n",
    "        # ✅ Commented out regex that splits on hyphens between letters:\n",
    "        # r\"(?<=[{a}])(?:{h})(?=[{a}])\".format(a=ALPHA, h=HYPHENS),\n",
    "        r\"(?<=[{a}0-9])[:<>=/](?=[{a}])\".format(a=ALPHA),\n",
    "    ]\n",
    ")\n",
    "\n",
    "infix_re = compile_infix_regex(infixes)\n",
    "nlp.tokenizer.infix_finditer = infix_re.finditer\n",
    "doc = nlp(\"mother-in-law\")\n",
    "print([t.text for t in doc]) # ['mother-in-law']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a578e7f-e588-4480-9984-0aaa7999cf7e",
   "metadata": {},
   "source": [
    "# Merging and splitting\n",
    "\n",
    "The Doc.retokenize context manager lets you merge and split tokens. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1e0a41d7-2663-4c35-8343-ce60828d4937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: ['I', 'live', 'in', 'New', 'York']\n",
      "After: ['I', 'live', 'in', 'New York']\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"I live in New York\")\n",
    "print(\"Before:\", [token.text for token in doc])\n",
    "\n",
    "with doc.retokenize() as retokenizer:\n",
    "    retokenizer.merge(doc[3:5], attrs={\"LEMMA\": \"new york\"})\n",
    "print(\"After:\", [token.text for token in doc])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734c584d-935f-4d24-b26b-04f65b310551",
   "metadata": {},
   "source": [
    "## Context Dependent Merge & Splits\n",
    "\n",
    "If an attribute in the attrs is a context-dependent token attribute, it will be applied to the underlying Token. For example LEMMA, POS or DEP only apply to a word in context, so they’re token attributes. If an attribute is a context-independent lexical attribute, it will be applied to the underlying Lexeme, the entry in the vocabulary. For example, LOWER or IS_STOP apply to all words of the same spelling, regardless of the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a19cac51-a576-4506-94fa-42de21d7c9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: ['I', 'live', 'in', 'NewYork']\n",
      "After: ['I', 'live', 'in', 'New', 'York']\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"I live in NewYork\")\n",
    "print(\"Before:\", [token.text for token in doc])\n",
    "\n",
    "with doc.retokenize() as retokenizer:\n",
    "    heads = [(doc[3], 1), doc[2]]\n",
    "    attrs = {\"POS\": [\"PROPN\", \"PROPN\"], \"DEP\": [\"pobj\", \"compound\"]}\n",
    "    retokenizer.split(doc[3], [\"New\", \"York\"], heads=heads, attrs=attrs)\n",
    "print(\"After:\", [token.text for token in doc])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546931db-e207-4950-9e68-2c4b1aed4fca",
   "metadata": {},
   "source": [
    "# Statistical sentence segmenter\n",
    "\n",
    "The SentenceRecognizer is a simple statistical component that only provides sentence boundaries. Along with being faster and smaller than the parser, its primary advantage is that it’s easier to train because it only requires annotated sentence boundaries rather than full dependency parses. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a3e1053b-a5c9-4857-ba00-6faf647a9796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sentence.\n",
      "This is another sentence.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nlp.enable_pipe(\"senter\")\n",
    "doc = nlp(\"This is a sentence. This is another sentence.\")\n",
    "for sent in doc.sents:\n",
    "    print(sent.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eae071d-9cb2-437b-9a45-841fa587a1eb",
   "metadata": {},
   "source": [
    "## Rule-based pipeline component\n",
    "\n",
    "The Sentencizer component is a pipeline component that splits sentences on punctuation like ., ! or ?. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e7f41f10-b493-4f6e-b335-fa844d4f61b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sentence.\n",
      "This is another sentence.\n"
     ]
    }
   ],
   "source": [
    "from spacy.lang.en import English\n",
    "\n",
    "nlp_e = English()  # just the language with no pipeline\n",
    "nlp_e.add_pipe(\"sentencizer\")\n",
    "doc = nlp_e(\"This is a sentence. This is another sentence.\")\n",
    "for sent in doc.sents:\n",
    "    print(sent.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b049a0-2fa0-4f8c-b064-6540e3b64dcf",
   "metadata": {},
   "source": [
    "## Mappings & Exceptions \n",
    "\n",
    "The AttributeRuler manages rule-based mappings and exceptions for all token-level attributes.\n",
    "\n",
    "provide exceptions for any token attributes\n",
    "map fine-grained tags to coarse-grained tags for languages without statistical morphologizers (replacing the v2.x tag_map in the language data)\n",
    "map token surface form + fine-grained tags to morphological features (replacing the v2.x morph_rules in the language data)\n",
    "specify the tags for space tokens (replacing hard-coded behavior in the tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c220164d-3645-4fe2-902d-f73597f1ed4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT DET\n",
      "WP PRON\n",
      "NNP PROPN\n",
      "NNP PROPN\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "text = \"I saw The Who perform. Who did you see?\"\n",
    "doc1 = nlp(text)\n",
    "print(doc1[2].tag_, doc1[2].pos_)  # DT DET\n",
    "print(doc1[3].tag_, doc1[3].pos_)  # WP PRON\n",
    "\n",
    "# Add attribute ruler with exception for \"The Who\" as NNP/PROPN NNP/PROPN\n",
    "ruler = nlp.get_pipe(\"attribute_ruler\")\n",
    "# Pattern to match \"The Who\"\n",
    "patterns = [[{\"LOWER\": \"the\"}, {\"TEXT\": \"Who\"}]]\n",
    "# The attributes to assign to the matched token\n",
    "attrs = {\"TAG\": \"NNP\", \"POS\": \"PROPN\"}\n",
    "# Add rules to the attribute ruler\n",
    "ruler.add(patterns=patterns, attrs=attrs, index=0)  # \"The\" in \"The Who\"\n",
    "ruler.add(patterns=patterns, attrs=attrs, index=1)  # \"Who\" in \"The Who\"\n",
    "\n",
    "doc2 = nlp(text)\n",
    "print(doc2[2].tag_, doc2[2].pos_)  # NNP PROPN\n",
    "print(doc2[3].tag_, doc2[3].pos_)  # NNP PROPN\n",
    "# The second \"Who\" remains unmodified\n",
    "print(doc2[5].tag_, doc2[5].pos_)  # WP PRON\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349b7386-619a-41e7-ba44-e796922bc9a7",
   "metadata": {},
   "source": [
    "# Word vectors and semantic similarity\n",
    "\n",
    "    Text: The original token text.\n",
    "    \n",
    "    has vector: Does the token have a vector representation?\n",
    "    \n",
    "    Vector norm: The L2 norm of the token’s vector (the square root of the sum of the values squared)\n",
    "    \n",
    "    OOV: Out-of-vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "38e41090-acf9-41c4-9080-812a268bf7d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Has_Vector</th>\n",
       "      <th>Vector_Norm</th>\n",
       "      <th>Is_OOV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dog</td>\n",
       "      <td>True</td>\n",
       "      <td>6.814786</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cat</td>\n",
       "      <td>True</td>\n",
       "      <td>7.370902</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>banana</td>\n",
       "      <td>True</td>\n",
       "      <td>7.646070</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>afskfsd</td>\n",
       "      <td>True</td>\n",
       "      <td>7.192256</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Text  Has_Vector  Vector_Norm  Is_OOV\n",
       "0      dog        True     6.814786    True\n",
       "1      cat        True     7.370902    True\n",
       "2   banana        True     7.646070    True\n",
       "3  afskfsd        True     7.192256    True"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = nlp(\"dog cat banana afskfsd\")\n",
    "data = []\n",
    "for token in tokens:\n",
    "    data.append([token.text, token.has_vector, token.vector_norm, token.is_oov])\n",
    "\n",
    "df = pd.DataFrame(data,columns=[\"Text\",\"Has_Vector\",\"Vector_Norm\",\"Is_OOV\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "27ee56e0-5b36-4515-b427-99e5c6ef5e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3296/90425054.py:5: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  data.append([doc1, doc2, doc1.similarity(doc2)])\n",
      "/tmp/ipykernel_3296/90425054.py:9: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Span.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  data.append([french_fries, burgers, french_fries.similarity(burgers)])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc1</th>\n",
       "      <th>Doc2</th>\n",
       "      <th>Similarity_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(I, like, salty, fries, and, hamburgers, .)</td>\n",
       "      <td>(Fast, food, tastes, very, good, .)</td>\n",
       "      <td>0.367600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(salty, fries)</td>\n",
       "      <td>hamburgers</td>\n",
       "      <td>0.433389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Doc1  \\\n",
       "0  (I, like, salty, fries, and, hamburgers, .)   \n",
       "1                               (salty, fries)   \n",
       "\n",
       "                                  Doc2  Similarity_Score  \n",
       "0  (Fast, food, tastes, very, good, .)          0.367600  \n",
       "1                           hamburgers          0.433389  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1 = nlp(\"I like salty fries and hamburgers.\")\n",
    "doc2 = nlp(\"Fast food tastes very good.\")\n",
    "data = []\n",
    "# Similarity of two documents\n",
    "data.append([doc1, doc2, doc1.similarity(doc2)])\n",
    "# Similarity of tokens and spans\n",
    "french_fries = doc1[2:4]\n",
    "burgers = doc1[5]\n",
    "data.append([french_fries, burgers, french_fries.similarity(burgers)])\n",
    "df = pd.DataFrame(data,columns=[\"Doc1\",\"Doc2\",\"Similarity_Score\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb733b24-9e7f-400f-b4e0-8bad6b6d4f2c",
   "metadata": {},
   "source": [
    "# Creating a custom language subclass\n",
    "\n",
    "If you want to customize multiple components of the language data or add support for a custom language or domain-specific “dialect”, you can also implement your own language subclass. The subclass should define two attributes: the lang (unique language code) and the Defaults defining the language data. For an overview of the available attributes that can be overwritten,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "546e82cc-9573-4c1f-a21e-cc682d4cfa6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en [False, False]\n",
      "custom_en [True, True]\n"
     ]
    }
   ],
   "source": [
    "from spacy.lang.en import English\n",
    "\n",
    "class CustomEnglishDefaults(English.Defaults):\n",
    "    stop_words = set([\"custom\", \"stop\"])\n",
    "\n",
    "class CustomEnglish(English):\n",
    "    lang = \"custom_en\"\n",
    "    Defaults = CustomEnglishDefaults\n",
    "\n",
    "nlp1 = English()\n",
    "nlp2 = CustomEnglish()\n",
    "\n",
    "print(nlp1.lang, [token.is_stop for token in nlp1(\"custom stop\")])\n",
    "print(nlp2.lang, [token.is_stop for token in nlp2(\"custom stop\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6798df8-f450-4b51-9ecf-9e4d28e828aa",
   "metadata": {},
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
