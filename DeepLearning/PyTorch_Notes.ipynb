{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30558,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "PyTorch_Notes",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset,DataLoader"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-12-24T01:43:32.505247Z",
          "iopub.execute_input": "2023-12-24T01:43:32.506055Z",
          "iopub.status.idle": "2023-12-24T01:43:36.875222Z",
          "shell.execute_reply.started": "2023-12-24T01:43:32.506015Z",
          "shell.execute_reply": "2023-12-24T01:43:36.873072Z"
        },
        "trusted": true,
        "id": "LD4Xh-TmcVLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Types of torch.nn Layers + torch.optim Optimization function + torch.nn Loss function"
      ],
      "metadata": {
        "id": "ILvvpXPVcVLj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "linear_layer = nn.Linear(in_features=10,out_features=5,bias=True)\n",
        "# conv1d -> text,conv2d -> heightXwidth (image),conv3d - heightXweightXtime (video)\n",
        "conv_1d = nn.Conv3d(in_channels=3,out_channels=5,kernel_size=3,stride=2,padding=2)\n",
        "\n",
        "#===============================================================================================\n",
        "#===============================================================================================\n",
        "\n",
        "## transformer layer\n",
        "transformer_model = nn.Transformer()\n",
        "# single encoder (embedding_dim=768)\n",
        "encoder_layer = nn.TransformerEncoderLayer(d_model=768,nhead=12)\n",
        "# stacked encoder\n",
        "transformer_encoder = nn.TransformerEncoder(encoder_layer=encoder_layer,num_layers=6)\n",
        "# single decoder layer\n",
        "decoder_layer = nn.TransformerDecoderLayer(d_model=768,nhead=12)\n",
        "# stacked decoder layer\n",
        "transformer_decoder = nn.TransformerDecoder(decoder_layer=decoder_layer,num_layers=6)\n",
        "\n",
        "#===============================================================================================\n",
        "#===============================================================================================\n",
        "\n",
        "# lstm cell\n",
        "lstm_cell = nn.LSTMCell(input_size=10,hidden_size=5)\n",
        "# Stack together LSTM cells - 3 stacked cells - similar for GRU\n",
        "lstm_stack = nn.LSTM(input_size=10,hidden_size=5, num_layers=3)\n",
        "bidirectional_lstm_stack = nn.LSTM(input_size=10,hidden_size=5,num_layers=3,bidirectional=True)\n",
        "\n",
        "#===============================================================================================\n",
        "#===============================================================================================\n",
        "# activation function - relu,sigmoid,softmax\n",
        "relu = nn.ReLU()\n",
        "# loss function\n",
        "mae = nn.L1Loss()\n",
        "mse = nn.MSELoss()\n",
        "binary_cross_entropy = nn.BCEWithLogitsLoss()\n",
        "multi_class_cross_entropy = nn.CrossEntropyLoss()\n",
        "\n",
        "#===============================================================================================\n",
        "#===============================================================================================\n",
        "\n",
        "# optimizer\n",
        "model = nn.Transformer()\n",
        "sgd = torch.optim.SGD(params=model.parameters(),lr=0.001)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-24T02:01:09.208256Z",
          "iopub.execute_input": "2023-12-24T02:01:09.208656Z",
          "iopub.status.idle": "2023-12-24T02:01:09.218551Z",
          "shell.execute_reply.started": "2023-12-24T02:01:09.208624Z",
          "shell.execute_reply": "2023-12-24T02:01:09.217026Z"
        },
        "trusted": true,
        "id": "IUAok_WUcVLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch Tensors"
      ],
      "metadata": {
        "id": "voPfW2tXcVLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "np_array = np.array([[1,2],[3,4]])\n",
        "torch_array = torch.from_numpy(np_array)\n",
        "print(f\"torch_array : {torch_array}\")\n",
        "torch_ones = torch.ones_like(torch_array,dtype=torch.float)\n",
        "print(f\"torch_ones : {torch_ones}\")\n",
        "shape = (2,3)\n",
        "torch_rand = torch.rand(shape)\n",
        "print(f\"torch_rand : {torch_rand}\")\n",
        "torch_arange = torch.arange(start=1,end=11,step=2)\n",
        "print(f\"torch_arange : \",{torch_arange})"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-28T02:32:00.460019Z",
          "iopub.execute_input": "2023-12-28T02:32:00.460489Z",
          "iopub.status.idle": "2023-12-28T02:32:00.472597Z",
          "shell.execute_reply.started": "2023-12-28T02:32:00.460457Z",
          "shell.execute_reply": "2023-12-28T02:32:00.471136Z"
        },
        "trusted": true,
        "id": "ivC7nF-IcVLv",
        "outputId": "10b8f632-f87d-4a46-804d-088267dd4c11"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "torch_array : tensor([[1, 2],\n        [3, 4]])\ntorch_ones : tensor([[1., 1.],\n        [1., 1.]])\ntorch_rand : tensor([[0.1420, 0.1922, 0.5319],\n        [0.3657, 0.0430, 0.8208]])\ntorch_arange :  {tensor([1, 3, 5, 7, 9])}\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor Indexing"
      ],
      "metadata": {
        "id": "N1EXCZjscVLy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.reshape(torch.arange(1,13,1,dtype=torch.float),(4,3))\n",
        "print(f\"First row: {x[0]}\")\n",
        "print(f\"First column: {x[:, 0]}\")\n",
        "print(f\"Last column: {x[..., -1]}\")\n",
        "x[:,1] = 0\n",
        "print(x)\n",
        "tensor1 = torch.randn(10, 3, 4)\n",
        "print(tensor1[:,0,0].shape,tensor1[0,:,0].shape,tensor1[0,0,:].shape)\n",
        "print(tensor1)\n",
        "tensor2 = torch.randn(4)\n",
        "print(tensor2)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-28T03:36:55.132456Z",
          "iopub.execute_input": "2023-12-28T03:36:55.133045Z",
          "iopub.status.idle": "2023-12-28T03:36:55.153552Z",
          "shell.execute_reply.started": "2023-12-28T03:36:55.133008Z",
          "shell.execute_reply": "2023-12-28T03:36:55.15176Z"
        },
        "trusted": true,
        "id": "PnxUpt1lcVLz",
        "outputId": "1ebc4dbc-c112-4e82-e632-a4631ec2c004"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "First row: tensor([1., 2., 3.])\nFirst column: tensor([ 1.,  4.,  7., 10.])\nLast column: tensor([ 3.,  6.,  9., 12.])\ntensor([[ 1.,  0.,  3.],\n        [ 4.,  0.,  6.],\n        [ 7.,  0.,  9.],\n        [10.,  0., 12.]])\ntorch.Size([10]) torch.Size([3]) torch.Size([4])\ntensor([[[-0.4198, -1.3901, -0.7433,  1.6252],\n         [-1.3204,  0.2975, -1.9061,  0.4013],\n         [-1.2086, -0.6729,  0.2693, -0.2020]],\n\n        [[-0.2129, -0.5784, -0.1382, -0.1359],\n         [-0.1326,  0.9448, -0.8960, -0.1384],\n         [-1.1900, -0.6642, -0.3136,  0.3689]],\n\n        [[-0.4662, -1.3043, -1.4399,  0.4012],\n         [ 1.5566,  1.7305, -0.0877,  0.4483],\n         [-0.0824, -0.9446, -0.5587, -0.3315]],\n\n        [[ 0.2831, -0.3476,  1.2822,  0.4452],\n         [ 1.3330, -2.1681,  0.7457,  1.1190],\n         [ 0.8063,  0.6081,  0.6591, -0.6953]],\n\n        [[-1.4361,  0.0067,  1.5265,  1.7683],\n         [-1.4769,  0.4061,  0.4140, -1.2963],\n         [-1.4096, -1.4380,  0.1303,  0.6771]],\n\n        [[-0.8026,  0.7763,  0.0867,  1.9739],\n         [-1.0366, -0.0450, -0.6429,  0.3087],\n         [-1.3665, -1.1721, -0.5223,  0.1377]],\n\n        [[ 0.1370, -1.9979,  0.2713, -0.1283],\n         [ 0.6508, -1.1412, -0.3425, -0.6489],\n         [-0.3668,  0.7319,  2.4437, -1.5481]],\n\n        [[-0.0282, -0.0609,  0.3651,  0.7016],\n         [ 0.5137,  0.2146,  1.3256,  0.4319],\n         [-0.4728,  0.4057, -1.1310,  0.3588]],\n\n        [[-1.1598,  1.1433,  0.9422,  0.5403],\n         [ 0.2999, -0.5343, -0.0566,  0.1676],\n         [ 0.8184,  0.7342,  0.3719,  0.0997]],\n\n        [[-0.4189,  0.3068, -0.8246, -0.1423],\n         [ 1.6314,  0.1968,  0.5517, -0.6386],\n         [-1.1487, -1.4260, -0.3797,  1.8733]]])\ntensor([ 0.6858, -0.5195,  0.6868, -0.3207])\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor Aggreration Operation"
      ],
      "metadata": {
        "id": "ltHg1_8LcVL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.ones(3, 4)\n",
        "print(f\"tensor : {tensor} \\n\")\n",
        "tensor.add_(5)\n",
        "print(\"tensor + 5 (inplace using add_ ) \",tensor)\n",
        "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
        "print(\"tensor concat : \",t1)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-28T02:35:13.92749Z",
          "iopub.execute_input": "2023-12-28T02:35:13.927959Z",
          "iopub.status.idle": "2023-12-28T02:35:13.938339Z",
          "shell.execute_reply.started": "2023-12-28T02:35:13.927923Z",
          "shell.execute_reply": "2023-12-28T02:35:13.937025Z"
        },
        "trusted": true,
        "id": "AZNMlblzcVL2",
        "outputId": "37e27bae-d6d4-41be-c21e-4518a98f314b"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "tensor : tensor([[1., 1., 1., 1.],\n        [1., 1., 1., 1.],\n        [1., 1., 1., 1.]]) \n\ntensor + 5 (inplace using add_ )  tensor([[6., 6., 6., 6.],\n        [6., 6., 6., 6.],\n        [6., 6., 6., 6.]])\ntensor concat :  tensor([[6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6.],\n        [6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6.],\n        [6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6.]])\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "if requires_grad=True then need to detach() before clone()"
      ],
      "metadata": {
        "id": "hvmAWqwDcVL3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.rand(2, 2, requires_grad=True) # turn on autograd\n",
        "print(\"a : \",a)\n",
        "\n",
        "b = a.clone()\n",
        "print(\"b : \",b)\n",
        "\n",
        "c = a.detach().clone()\n",
        "print(\"c : \",c)\n",
        "\n",
        "try:\n",
        "    assert b is a\n",
        "except AssertionError as e:\n",
        "    print(e)\n",
        "\n",
        "a = torch.rand(3, 226, 226)\n",
        "e = torch.rand(1,5)\n",
        "c = a.clone()\n",
        "\n",
        "b = a.unsqueeze(0)\n",
        "d = c.squeeze(0)\n",
        "f = e.squeeze(0)\n",
        "print(\"a.unsqueeze(0) : \",a.shape,b.shape)\n",
        "print(\"a.squeeze(0) : \",a.shape,d.shape)\n",
        "print(\"e.squeeze(0) : \",e.shape,f.shape)"
      ],
      "metadata": {
        "id": "r1W9q9mvcVL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Torch Aggregation - groupby"
      ],
      "metadata": {
        "id": "AuViruracVL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "samples = torch.Tensor([\n",
        "    [0.1, 0.1],    #-> group / class 1\n",
        "    [0.2, 0.2],    #-> group / class 2\n",
        "    [0.4, 0.4],    #-> group / class 2\n",
        "    [0.0, 0.0]     #-> group / class 0\n",
        "])\n",
        "\n",
        "labels = torch.LongTensor([1,2,2,0])\n",
        "\n",
        "label_size = 3\n",
        "sample_dim = samples.size(1)\n",
        "print(\"sample_dim \",sample_dim)\n",
        "index = labels.unsqueeze(1)\n",
        "print(\"labels.unsqueeze(1) \",index)\n",
        "index = index.repeat((1, sample_dim))\n",
        "print(\"index.repeat((1, sample_dim)) \",index)\n",
        "\n",
        "res = torch.ones(label_size, sample_dim, dtype=samples.dtype)\n",
        "print(\"res \",res)\n",
        "res.scatter_(0, index, samples, reduce='multiply')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-28T03:13:46.269464Z",
          "iopub.execute_input": "2023-12-28T03:13:46.269971Z",
          "iopub.status.idle": "2023-12-28T03:13:46.287578Z",
          "shell.execute_reply.started": "2023-12-28T03:13:46.269932Z",
          "shell.execute_reply": "2023-12-28T03:13:46.286052Z"
        },
        "trusted": true,
        "id": "QKsnT5qocVL5",
        "outputId": "43fa54bb-fff2-4b34-f17e-0d532f592690"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "sample_dim  2\nlabels.unsqueeze(1)  tensor([[1],\n        [2],\n        [2],\n        [0]])\nindex.repeat((1, sample_dim))  tensor([[1, 1],\n        [2, 2],\n        [2, 2],\n        [0, 0]])\nres  tensor([[1., 1.],\n        [1., 1.],\n        [1., 1.]])\n",
          "output_type": "stream"
        },
        {
          "execution_count": 33,
          "output_type": "execute_result",
          "data": {
            "text/plain": "tensor([[0.0000, 0.0000],\n        [0.1000, 0.1000],\n        [0.0800, 0.0800]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "F7rSfwy0cVL5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Matrix Multiplication\n",
        "\n",
        "    torch.mm - performs a matrix multiplication without broadcasting - (2D tensor) by (2D tensor)\n",
        "    torch.mul - performs a elementwise multiplication with broadcasting - (Tensor) by (Tensor or Number)\n",
        "    torch.matmul - matrix product with broadcasting - (Tensor) by (Tensor) with different behaviors depending on the tensor shapes (dot product, matrix product, batched matrix products).\n",
        "    \n"
      ],
      "metadata": {
        "id": "2JZi5TakcVL6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "    torch.mm - performs a matrix multiplication without broadcasting\n",
        "It expects two 2D tensors so n×m * m×p = n×p"
      ],
      "metadata": {
        "id": "5SRX46-fcVL6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = torch.ones(3, 4)\n",
        "x2 = torch.reshape(torch.arange(1,13,1,dtype=torch.float),(4,3))\n",
        "print(f\"x1 : {x1.shape} ,x2 : {x2.shape}\")\n",
        "y1 = x1 @ x2\n",
        "y2 = x1.matmul(x2)\n",
        "assert torch.all(torch.eq(y1,y2)).item()==True\n",
        "y3 = torch.mm(x1, x2)\n",
        "\n",
        "# assert torch.all(torch.eq(y3,y2)).item()==True\n",
        "print(\"Matrix Multiplication : works with only matching dimensions\")\n",
        "print(f\"y1 = x1 @ x2 : shape {y1.shape} : {y1}\")\n",
        "print(f\"y2 = x1.matmul(x2) : shape {y2.shape} : {y2}\")\n",
        "print(f\"y3 = torch.mm(x1, x2) : shape {y3.shape} : {y3}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-28T03:48:47.247543Z",
          "iopub.execute_input": "2023-12-28T03:48:47.248082Z",
          "iopub.status.idle": "2023-12-28T03:48:47.260929Z",
          "shell.execute_reply.started": "2023-12-28T03:48:47.248048Z",
          "shell.execute_reply": "2023-12-28T03:48:47.259625Z"
        },
        "trusted": true,
        "id": "SB2H-YS0cVL6",
        "outputId": "455e5e76-e52c-41a7-f127-51fc74c27227"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "x1 : torch.Size([3, 4]) ,x2 : torch.Size([4, 3])\nMatrix Multiplication : works with only matching dimensions\ny1 = x1 @ x2 : shape torch.Size([3, 3]) : tensor([[22., 26., 30.],\n        [22., 26., 30.],\n        [22., 26., 30.]])\ny2 = x1.matmul(x2) : shape torch.Size([3, 3]) : tensor([[22., 26., 30.],\n        [22., 26., 30.],\n        [22., 26., 30.]])\ny3 = torch.mm(x1, x2) : shape torch.Size([3, 3]) : tensor([[22., 26., 30.],\n        [22., 26., 30.],\n        [22., 26., 30.]])\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "    torch.mul - performs a elementwise multiplication with broadcasting - (Tensor) by (Tensor or Number)\n",
        "\n",
        "Docs: https://pytorch.org/docs/stable/generated/torch.mul.html\n",
        "\n",
        "torch.mul does not perform a matrix multiplication. It broadcasts two tensors and performs an elementwise multiplication. So when you uses it with tensors 1x4 * 4x1 it will work similar to:"
      ],
      "metadata": {
        "id": "5u928cyrcVL7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.FloatTensor([[1], [2], [3]])\n",
        "b = torch.FloatTensor([[1, 10, 100, 1000]])\n",
        "a, b = torch.broadcast_tensors(a, b)\n",
        "c = a * b\n",
        "d = torch.mul(a,b)\n",
        "print(a)\n",
        "print(b)\n",
        "assert torch.all(torch.eq(c,d)).item()==True\n",
        "print(c)\n",
        "print(d)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-28T03:27:55.558708Z",
          "iopub.execute_input": "2023-12-28T03:27:55.559151Z",
          "iopub.status.idle": "2023-12-28T03:27:55.569844Z",
          "shell.execute_reply.started": "2023-12-28T03:27:55.559117Z",
          "shell.execute_reply": "2023-12-28T03:27:55.568693Z"
        },
        "trusted": true,
        "id": "V4c6WYcIcVL7",
        "outputId": "487c07c5-51bf-437f-fe40-156eacbe703e"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "tensor([[1., 1., 1., 1.],\n        [2., 2., 2., 2.],\n        [3., 3., 3., 3.]])\ntensor([[   1.,   10.,  100., 1000.],\n        [   1.,   10.,  100., 1000.],\n        [   1.,   10.,  100., 1000.]])\ntensor([[1.0000e+00, 1.0000e+01, 1.0000e+02, 1.0000e+03],\n        [2.0000e+00, 2.0000e+01, 2.0000e+02, 2.0000e+03],\n        [3.0000e+00, 3.0000e+01, 3.0000e+02, 3.0000e+03]])\ntensor([[1.0000e+00, 1.0000e+01, 1.0000e+02, 1.0000e+03],\n        [2.0000e+00, 2.0000e+01, 2.0000e+02, 2.0000e+03],\n        [3.0000e+00, 3.0000e+01, 3.0000e+02, 3.0000e+03]])\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "    torch.matmul\n",
        "\n",
        "It is better to check out the official documentation https://pytorch.org/docs/stable/generated/torch.matmul.html as it uses different modes depending on the input tensors. It may perform dot product, matrix-matrix product or batched matrix products with broadcasting."
      ],
      "metadata": {
        "id": "8lQiTNjucVL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor1 = torch.randn(10, 3, 4)\n",
        "tensor2 = torch.randn(4)\n",
        "print(tensor1[:,0,0].shape,tensor1[0,:,0].shape,tensor1[0,0,:].shape)\n",
        "print(tensor2.shape)\n",
        "tensor3 = torch.matmul(tensor1,tensor2)\n",
        "print(tensor3.shape)\n",
        "\n",
        "# 3x1x3\n",
        "a = torch.FloatTensor([[[1, 2, 3]], [[3, 4, 5]], [[6, 7, 8]]])\n",
        "# 3\n",
        "b = torch.FloatTensor([1, 10, 100])\n",
        "r1 = torch.matmul(a, b)\n",
        "\n",
        "r2 = torch.stack((\n",
        "    torch.matmul(a[0], b),\n",
        "    torch.matmul(a[1], b),\n",
        "    torch.matmul(a[2], b),\n",
        "))\n",
        "assert torch.allclose(r1, r2)\n",
        "print(a.shape,b.shape,r1.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-28T03:42:10.890867Z",
          "iopub.execute_input": "2023-12-28T03:42:10.891342Z",
          "iopub.status.idle": "2023-12-28T03:42:10.904673Z",
          "shell.execute_reply.started": "2023-12-28T03:42:10.891305Z",
          "shell.execute_reply": "2023-12-28T03:42:10.903003Z"
        },
        "trusted": true,
        "id": "OjZmqjnQcVL8",
        "outputId": "0f2940d6-0e36-4593-a8dd-9505023cfaca"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "torch.Size([10]) torch.Size([3]) torch.Size([4])\ntorch.Size([4])\ntorch.Size([10, 3])\ntorch.Size([3, 1, 3]) torch.Size([3]) torch.Size([3, 1])\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.ones(4, 3, 2)\n",
        "b = torch.rand(   3)     # trying to multiply a * b will give a runtime error\n",
        "c = b.unsqueeze(1)       # change to a 2-dimensional tensor, adding new dim at the end\n",
        "print(\"After broadcasting b : \", c.shape)\n",
        "print(\"Broadcasing internally : \",torch.mul(a,c).shape)            # broadcasting works again!\n",
        "\n",
        "output3d = torch.rand(6, 20, 20)\n",
        "print(\"output3d : \",output3d.shape)\n",
        "\n",
        "input1d = output3d.reshape(6 * 20 * 20)\n",
        "print(\"input1d : \",input1d.shape)\n",
        "\n",
        "# can also call it as a method on the torch module:\n",
        "print(\"same as above but using torch : \",torch.reshape(output3d, (6 * 20 * 20,)).shape)"
      ],
      "metadata": {
        "id": "SUyPu0YZcVL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch Common Math function"
      ],
      "metadata": {
        "id": "rnUtWlrhcVL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import math\n",
        "\n",
        "# common functions\n",
        "a = torch.rand(2, 4) * 2 - 1\n",
        "print('Common functions:')\n",
        "print(torch.abs(a))\n",
        "print(torch.ceil(a))\n",
        "print(torch.floor(a))\n",
        "print(torch.clamp(a, -0.5, 0.5))\n",
        "\n",
        "# trigonometric functions and their inverses\n",
        "angles = torch.tensor([0, math.pi / 4, math.pi / 2, 3 * math.pi / 4])\n",
        "sines = torch.sin(angles)\n",
        "inverses = torch.asin(sines)\n",
        "print('\\nSine and arcsine:')\n",
        "print(angles)\n",
        "print(sines)\n",
        "print(inverses)\n",
        "\n",
        "# bitwise operations\n",
        "print('\\nBitwise XOR:')\n",
        "b = torch.tensor([1, 5, 11])\n",
        "c = torch.tensor([2, 7, 10])\n",
        "print(torch.bitwise_xor(b, c))\n",
        "\n",
        "# comparisons:\n",
        "print('\\nBroadcasted, element-wise equality comparison:')\n",
        "d = torch.tensor([[1., 2.], [3., 4.]])\n",
        "e = torch.ones(1, 2)  # many comparison ops support broadcasting!\n",
        "print(torch.eq(d, e)) # returns a tensor of type bool\n",
        "\n",
        "# reductions:\n",
        "print('\\nReduction ops:')\n",
        "print(torch.max(d))        # returns a single-element tensor\n",
        "print(torch.max(d).item()) # extracts the value from the returned tensor\n",
        "print(torch.mean(d))       # average\n",
        "print(torch.std(d))        # standard deviation\n",
        "print(torch.prod(d))       # product of all numbers\n",
        "print(torch.unique(torch.tensor([1, 2, 1, 2, 1, 2]))) # filter unique elements\n",
        "\n",
        "# vector and linear algebra operations\n",
        "v1 = torch.tensor([1., 0., 0.])         # x unit vector\n",
        "v2 = torch.tensor([0., 1., 0.])         # y unit vector\n",
        "m1 = torch.rand(2, 2)                   # random matrix\n",
        "m2 = torch.tensor([[3., 0.], [0., 3.]]) # three times identity matrix\n",
        "\n",
        "print('\\nVectors & Matrices:')\n",
        "print(torch.cross(v2, v1)) # negative of z unit vector (v1 x v2 == -v2 x v1)\n",
        "print(m1)\n",
        "m3 = torch.matmul(m1, m2)\n",
        "print(m3)                  # 3 times m1\n",
        "print(torch.svd(m3))       # singular value decomposition"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-27T01:50:37.961785Z",
          "iopub.execute_input": "2023-12-27T01:50:37.963441Z",
          "iopub.status.idle": "2023-12-27T01:50:38.001452Z",
          "shell.execute_reply.started": "2023-12-27T01:50:37.963395Z",
          "shell.execute_reply": "2023-12-27T01:50:38.000329Z"
        },
        "trusted": true,
        "id": "qaQgjCrscVL9",
        "outputId": "e5edfa90-bd5c-4401-98b9-906df8591bdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Common functions:\ntensor([[0.8587, 0.0493, 0.9242, 0.1247],\n        [0.0059, 0.8742, 0.3704, 0.4161]])\ntensor([[-0., -0., 1., -0.],\n        [1., 1., -0., -0.]])\ntensor([[-1., -1.,  0., -1.],\n        [ 0.,  0., -1., -1.]])\ntensor([[-0.5000, -0.0493,  0.5000, -0.1247],\n        [ 0.0059,  0.5000, -0.3704, -0.4161]])\n\nSine and arcsine:\ntensor([0.0000, 0.7854, 1.5708, 2.3562])\ntensor([0.0000, 0.7071, 1.0000, 0.7071])\ntensor([0.0000, 0.7854, 1.5708, 0.7854])\n\nBitwise XOR:\ntensor([3, 2, 1])\n\nBroadcasted, element-wise equality comparison:\ntensor([[ True, False],\n        [False, False]])\n\nReduction ops:\ntensor(4.)\n4.0\ntensor(2.5000)\ntensor(1.2910)\ntensor(24.)\ntensor([1, 2])\n\nVectors & Matrices:\ntensor([ 0.,  0., -1.])\ntensor([[0.1393, 0.9677],\n        [0.4260, 0.3730]])\ntensor([[0.4178, 2.9031],\n        [1.2780, 1.1191]])\ntorch.return_types.svd(\nU=tensor([[-0.8952, -0.4456],\n        [-0.4456,  0.8952]]),\nS=tensor([3.2382, 1.0014]),\nV=tensor([[-0.2914,  0.9566],\n        [-0.9566, -0.2914]]))\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yxhu7pgbcVL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "x = torch.arange(1, 11, 1)\n",
        "print(\"Original Tensor:\", x)\n",
        "\n",
        "# Ensure the index tensor is of dtype torch.int64\n",
        "one_hot_encoded = F.one_hot(torch.tensor(x - 1), num_classes=len(x))\n",
        "print(\"One-Hot Encoded Tensor:\\n\", one_hot_encoded.float())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-25T01:58:52.873991Z",
          "iopub.execute_input": "2023-12-25T01:58:52.875131Z",
          "iopub.status.idle": "2023-12-25T01:58:56.959261Z",
          "shell.execute_reply.started": "2023-12-25T01:58:52.875087Z",
          "shell.execute_reply": "2023-12-25T01:58:56.958067Z"
        },
        "trusted": true,
        "id": "Q6l6XpOQcVL-",
        "outputId": "38d80862-c5e9-43b0-ec98-681daf2ab0ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Original Tensor: tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\nOne-Hot Encoded Tensor:\n tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_32/2904155138.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  one_hot_encoded = F.one_hot(torch.tensor(x - 1), num_classes=len(x))\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inp = torch.eye(4, 5, requires_grad=True)\n",
        "out = (inp+1).pow(2).t()\n",
        "print(\"inp : \\n\",inp)\n",
        "print(\"out : \\n\",out)\n",
        "out.backward(torch.ones_like(out), retain_graph=True)\n",
        "print(f\"First call\\n{inp.grad}\")\n",
        "out.backward(torch.ones_like(out), retain_graph=True)\n",
        "print(f\"\\nSecond call\\n{inp.grad}\")\n",
        "inp.grad.zero_()\n",
        "out.backward(torch.ones_like(out), retain_graph=True)\n",
        "print(f\"\\nCall after zeroing gradients\\n{inp.grad}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-25T02:00:35.343701Z",
          "iopub.execute_input": "2023-12-25T02:00:35.344091Z",
          "iopub.status.idle": "2023-12-25T02:00:35.358043Z",
          "shell.execute_reply.started": "2023-12-25T02:00:35.34406Z",
          "shell.execute_reply": "2023-12-25T02:00:35.356698Z"
        },
        "trusted": true,
        "id": "MtPVkATOcVL-",
        "outputId": "f0a3e63f-9bc8-4498-dbcd-1948fe5def43"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "inp : \n tensor([[1., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0.],\n        [0., 0., 1., 0., 0.],\n        [0., 0., 0., 1., 0.]], requires_grad=True)\nout : \n tensor([[4., 1., 1., 1.],\n        [1., 4., 1., 1.],\n        [1., 1., 4., 1.],\n        [1., 1., 1., 4.],\n        [1., 1., 1., 1.]], grad_fn=<TBackward0>)\nFirst call\ntensor([[4., 2., 2., 2., 2.],\n        [2., 4., 2., 2., 2.],\n        [2., 2., 4., 2., 2.],\n        [2., 2., 2., 4., 2.]])\n\nSecond call\ntensor([[8., 4., 4., 4., 4.],\n        [4., 8., 4., 4., 4.],\n        [4., 4., 8., 4., 4.],\n        [4., 4., 4., 8., 4.]])\n\nCall after zeroing gradients\ntensor([[4., 2., 2., 2., 2.],\n        [2., 4., 2., 2., 2.],\n        [2., 2., 4., 2., 2.],\n        [2., 2., 2., 4., 2.]])\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "class LegendrePolynomial3(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx,x):\n",
        "        ctx.save_for_backward(x)\n",
        "        return 0.5 * (5*x**3 - 3*x)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx,grad_out):\n",
        "        x, = ctx.saved_tensors\n",
        "        return grad_out*1.5*(5*x**2-1)\n",
        "\n",
        "device,dtype = torch.device(\"cpu\"),torch.float\n",
        "x = torch.linspace(-math.pi,math.pi,10,dtype=dtype)\n",
        "y = torch.sin(x)\n",
        "print(\"x : \",x)\n",
        "print(\"y : \",y)\n",
        "a = torch.full((), 0.0, device=device, dtype=dtype, requires_grad=True)\n",
        "b = torch.full((), -1.0, device=device, dtype=dtype, requires_grad=True)\n",
        "c = torch.full((), 0.0, device=device, dtype=dtype, requires_grad=True)\n",
        "d = torch.full((), 0.3, device=device, dtype=dtype, requires_grad=True)\n",
        "print(\"a : \",a)\n",
        "print(\"b : \",b)\n",
        "lr = 5e-6\n",
        "\n",
        "for it in range(100):\n",
        "    # forward pass\n",
        "    P3 = LegendrePolynomial3.apply\n",
        "    y_pred = a+b*P3(c+d*x)\n",
        "    loss = (y-y_pred).pow(2).sum()\n",
        "    if it%10==0:\n",
        "        print(f\"iter : {it} loss : {loss.item()}\")\n",
        "    loss.backward()\n",
        "    # update grad\n",
        "    with torch.no_grad():\n",
        "        a -=lr*a.grad\n",
        "        b -=lr*b.grad\n",
        "        c -=lr*c.grad\n",
        "        d -=lr*d.grad\n",
        "        a.grad = None\n",
        "        b.grad = None\n",
        "        c.grad = None\n",
        "        d.grad = None\n",
        "\n",
        "print(f'Result: y = {a.item()} + {b.item()} * P3({c.item()} + {d.item()} x)')\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-25T02:33:34.434601Z",
          "iopub.execute_input": "2023-12-25T02:33:34.435007Z",
          "iopub.status.idle": "2023-12-25T02:33:34.489082Z",
          "shell.execute_reply.started": "2023-12-25T02:33:34.434976Z",
          "shell.execute_reply": "2023-12-25T02:33:34.487671Z"
        },
        "trusted": true,
        "id": "4zMGdl5FcVL-",
        "outputId": "8ec7cb09-3cb8-4eda-fda6-b29b56f4842b"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "x :  tensor([-3.1416, -2.4435, -1.7453, -1.0472, -0.3491,  0.3491,  1.0472,  1.7453,\n         2.4435,  3.1416])\ny :  tensor([ 8.7423e-08, -6.4279e-01, -9.8481e-01, -8.6603e-01, -3.4202e-01,\n         3.4202e-01,  8.6603e-01,  9.8481e-01,  6.4279e-01, -8.7423e-08])\na :  tensor(0., requires_grad=True)\nb :  tensor(-1., requires_grad=True)\niter : 0 loss : 2.62017822265625\niter : 10 loss : 2.4684810638427734\niter : 20 loss : 2.3406341075897217\niter : 30 loss : 2.2319769859313965\niter : 40 loss : 2.138925790786743\niter : 50 loss : 2.058706045150757\niter : 60 loss : 1.9891233444213867\niter : 70 loss : 1.9284296035766602\niter : 80 loss : 1.8752241134643555\niter : 90 loss : 1.8283681869506836\nResult: y = -3.5762792467003424e-12 + -1.0005356073379517 * P3(3.2782552714105684e-12 + 0.2799958288669586 x)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class LeNet(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        # 1 input image channel (black & white), 6 output channels, 5x5 square convolution\n",
        "        # kernel\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5*5 from image dimension\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Max pooling over a (2, 2) window\n",
        "        print(\"Before 1st Max-pooling \",x.shape)\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        print(\"After 1st Max-pooling \",x.shape)\n",
        "        # If the size is a square you can only specify a single number\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        print(\"After 2nd Max-pooling \",x.shape)\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        print(\"After flatten \",x.shape)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        print(\"After 1st FC \",x.shape)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        print(\"After 2nd FC \",x.shape)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "\n",
        "\n",
        "net = LeNet()\n",
        "print(net)                         # what does the object tell us about itself?\n",
        "\n",
        "x = torch.rand(1, 1, 32, 32)   # stand-in for a 32x32 black & white image\n",
        "print('\\nImage batch shape: ',x.shape)\n",
        "print()\n",
        "output = net(x)                # we don't call forward() directly\n",
        "print('\\nRaw output: ',output.shape)\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-27T03:35:40.350017Z",
          "iopub.execute_input": "2023-12-27T03:35:40.350458Z",
          "iopub.status.idle": "2023-12-27T03:35:40.372634Z",
          "shell.execute_reply.started": "2023-12-27T03:35:40.350428Z",
          "shell.execute_reply": "2023-12-27T03:35:40.371615Z"
        },
        "trusted": true,
        "id": "UD228qTWcVL_",
        "outputId": "992ac22b-fe63-4201-ca64-be6afe08f271"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "LeNet(\n  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n  (fc1): Linear(in_features=400, out_features=120, bias=True)\n  (fc2): Linear(in_features=120, out_features=84, bias=True)\n  (fc3): Linear(in_features=84, out_features=10, bias=True)\n)\n\nImage batch shape:  torch.Size([1, 1, 32, 32])\n\nBefore 1st Max-pooling  torch.Size([1, 1, 32, 32])\nAfter 1st Max-pooling  torch.Size([1, 6, 14, 14])\nAfter 2nd Max-pooling  torch.Size([1, 16, 5, 5])\nAfter flatten  torch.Size([1, 400])\nAfter 1st FC  torch.Size([1, 120])\nAfter 2nd FC  torch.Size([1, 84])\n\nRaw output:  torch.Size([1, 10])\ntensor([[[ 0.0616, -0.0301,  0.0087, -0.0128,  0.0276],\n         [-0.0459,  0.0670,  0.0641,  0.0208, -0.0161],\n         [-0.0261, -0.0803,  0.0063,  0.0082,  0.0133],\n         [-0.0082, -0.0273, -0.0540, -0.0452,  0.0129],\n         [-0.0126,  0.0143, -0.0307, -0.0135, -0.0357]],\n\n        [[ 0.0010,  0.0365, -0.0153, -0.0238, -0.0104],\n         [-0.0399,  0.0632, -0.0516,  0.0447, -0.0349],\n         [-0.0505, -0.0107, -0.0170, -0.0058, -0.0049],\n         [ 0.0018, -0.0083,  0.0121,  0.0597, -0.0054],\n         [-0.0278,  0.0081, -0.0208, -0.0416, -0.0489]],\n\n        [[-0.0260, -0.0688, -0.0732,  0.0570, -0.0730],\n         [ 0.0047,  0.0460,  0.0269,  0.0083, -0.0406],\n         [ 0.0194, -0.0147,  0.0345,  0.0519,  0.0639],\n         [ 0.0530, -0.0488,  0.0150, -0.0010, -0.0602],\n         [ 0.0692,  0.0669, -0.0303,  0.0806,  0.0388]],\n\n        [[ 0.0632, -0.0594,  0.0716, -0.0373, -0.0674],\n         [-0.0422,  0.0799,  0.0541,  0.0331, -0.0541],\n         [-0.0677,  0.0811, -0.0529,  0.0190,  0.0592],\n         [-0.0535,  0.0182, -0.0779,  0.0605,  0.0441],\n         [ 0.0679,  0.0309,  0.0546, -0.0753, -0.0798]],\n\n        [[-0.0390,  0.0152, -0.0527, -0.0113, -0.0710],\n         [-0.0713,  0.0231, -0.0789,  0.0657, -0.0745],\n         [-0.0583, -0.0722, -0.0044,  0.0290, -0.0570],\n         [ 0.0129, -0.0567, -0.0021,  0.0486, -0.0058],\n         [ 0.0024, -0.0399,  0.0235,  0.0798, -0.0372]]],\n       grad_fn=<SliceBackward0>)\nNone\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "BATCH_SIZE = 4\n",
        "DIM_IN = 10\n",
        "HIDDEN_SIZE = 5\n",
        "DIM_OUT = 3\n",
        "\n",
        "class TinyModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(TinyModel, self).__init__()\n",
        "\n",
        "        self.layer1 = torch.nn.Linear(DIM_IN,HIDDEN_SIZE)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.layer2 = torch.nn.Linear(HIDDEN_SIZE,DIM_OUT)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        print(\"After layer1 : \",x.shape)\n",
        "        x = self.relu(x)\n",
        "        print(\"After relu : \",x.shape)\n",
        "        x = self.layer2(x)\n",
        "        print(\"After layer2 : \",x.shape)\n",
        "        return x\n",
        "\n",
        "some_input = torch.randn(BATCH_SIZE, DIM_IN, requires_grad=False)\n",
        "ideal_output = torch.randn(BATCH_SIZE, DIM_OUT, requires_grad=False)\n",
        "\n",
        "model = TinyModel()\n",
        "print(model)\n",
        "\n",
        "print('The model:')\n",
        "print(model)\n",
        "\n",
        "print('\\n\\nJust one layer:')\n",
        "print(model.layer2)\n",
        "\n",
        "print('\\n\\nModel params:')\n",
        "for param in model.parameters():\n",
        "    print(param)\n",
        "\n",
        "print('\\n\\nLayer2 params:')\n",
        "for param in model.layer2.parameters():\n",
        "    print(param)\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-28T01:29:04.089413Z",
          "iopub.execute_input": "2023-12-28T01:29:04.090387Z",
          "iopub.status.idle": "2023-12-28T01:29:08.151234Z",
          "shell.execute_reply.started": "2023-12-28T01:29:04.090344Z",
          "shell.execute_reply": "2023-12-28T01:29:08.150189Z"
        },
        "trusted": true,
        "id": "H7KS59stcVMA",
        "outputId": "d0cb6a96-a5a6-49ec-f892-fa200d428204"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "TinyModel(\n  (layer1): Linear(in_features=10, out_features=5, bias=True)\n  (relu): ReLU()\n  (layer2): Linear(in_features=5, out_features=3, bias=True)\n)\nThe model:\nTinyModel(\n  (layer1): Linear(in_features=10, out_features=5, bias=True)\n  (relu): ReLU()\n  (layer2): Linear(in_features=5, out_features=3, bias=True)\n)\n\n\nJust one layer:\nLinear(in_features=5, out_features=3, bias=True)\n\n\nModel params:\nParameter containing:\ntensor([[ 0.1707,  0.2802,  0.3141,  0.1493,  0.2285,  0.0542,  0.1041,  0.0995,\n         -0.1608,  0.1545],\n        [ 0.2470, -0.1126, -0.2651,  0.1784, -0.0713, -0.1379, -0.0692,  0.1331,\n         -0.1114,  0.1604],\n        [-0.0364, -0.2262,  0.0610,  0.1969,  0.0008,  0.2661,  0.0582, -0.2541,\n         -0.0842, -0.3015],\n        [ 0.2489, -0.2897,  0.0012,  0.2174,  0.1837, -0.2974, -0.1919, -0.2012,\n         -0.2468, -0.2838],\n        [ 0.1434,  0.0558,  0.3025,  0.2021, -0.2085, -0.1412, -0.1651, -0.2545,\n         -0.3015,  0.0285]], requires_grad=True)\nParameter containing:\ntensor([ 0.1730, -0.0979,  0.0790,  0.1789, -0.0176], requires_grad=True)\nParameter containing:\ntensor([[ 0.1351, -0.2073, -0.1421,  0.3038, -0.4342],\n        [ 0.0886, -0.3375,  0.4023,  0.2033,  0.0395],\n        [-0.3346,  0.3087,  0.1119, -0.1473,  0.1628]], requires_grad=True)\nParameter containing:\ntensor([-0.2228,  0.1992, -0.1283], requires_grad=True)\n\n\nLayer2 params:\nParameter containing:\ntensor([[ 0.1351, -0.2073, -0.1421,  0.3038, -0.4342],\n        [ 0.0886, -0.3375,  0.4023,  0.2033,  0.0395],\n        [-0.3346,  0.3087,  0.1119, -0.1473,  0.1628]], requires_grad=True)\nParameter containing:\ntensor([-0.2228,  0.1992, -0.1283], requires_grad=True)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"before weights update \")\n",
        "print(model.layer2.weight[0][0:10]) # just a small slice\n",
        "print(model.layer2.weight.grad)\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "prediction = model(some_input)\n",
        "\n",
        "loss = (ideal_output - prediction).pow(2).sum()\n",
        "print(\"loss : \",loss)\n",
        "\n",
        "loss.backward()\n",
        "print(\"weights after backward pass : \")\n",
        "print(model.layer2.weight[0][0:10])\n",
        "print(model.layer2.weight.grad[0][0:10])\n",
        "\n",
        "optimizer.step()\n",
        "print(\"weights after backward pass + grad optimized : \")\n",
        "print(model.layer2.weight[0][0:10])\n",
        "print(model.layer2.weight.grad[0][0:10])\n",
        "\n",
        "optimizer.zero_grad(set_to_none=False)\n",
        "print(\"weights after backward pass + grad optimized + optimizer.zero_grad : \")\n",
        "print(model.layer2.weight[0][0:10])\n",
        "print(model.layer2.weight.grad[0][0:10])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-28T01:29:08.152957Z",
          "iopub.execute_input": "2023-12-28T01:29:08.153494Z",
          "iopub.status.idle": "2023-12-28T01:29:08.217809Z",
          "shell.execute_reply.started": "2023-12-28T01:29:08.15346Z",
          "shell.execute_reply": "2023-12-28T01:29:08.216915Z"
        },
        "trusted": true,
        "id": "X3AvfC75cVMB",
        "outputId": "c1eea319-9173-419d-97ce-b8ebe84f5457"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "before weights update \ntensor([ 0.1351, -0.2073, -0.1421,  0.3038, -0.4342], grad_fn=<SliceBackward0>)\nNone\nAfter layer1 :  torch.Size([4, 5])\nAfter relu :  torch.Size([4, 5])\nAfter layer2 :  torch.Size([4, 3])\nloss :  tensor(19.0096, grad_fn=<SumBackward0>)\nweights after backward pass : \ntensor([ 0.1351, -0.2073, -0.1421,  0.3038, -0.4342], grad_fn=<SliceBackward0>)\ntensor([-0.2993,  0.7222,  0.9651,  2.6914,  0.4884])\nweights after backward pass + grad optimized : \ntensor([ 0.1354, -0.2080, -0.1431,  0.3011, -0.4347], grad_fn=<SliceBackward0>)\ntensor([-0.2993,  0.7222,  0.9651,  2.6914,  0.4884])\nweights after backward pass + grad optimized + optimizer.zero_grad : \ntensor([ 0.1354, -0.2080, -0.1431,  0.3011, -0.4347], grad_fn=<SliceBackward0>)\ntensor([0., 0., 0., 0., 0.])\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "vocab_size is the number of words in the input vocabulary. Each word is a one-hot vector (or unit vector) in a vocab_size-dimensional space.\n",
        "\n",
        "tagset_size is the number of tags in the output set.\n",
        "\n",
        "embedding_dim is the size of the embedding space for the vocabulary. An embedding maps a vocabulary onto a low-dimensional space, where words with similar meanings are close together in the space.\n",
        "\n",
        "hidden_dim is the size of the LSTM’s memory.\n",
        "\n",
        "The input will be a sentence with the words represented as indices of one-hot vectors. The embedding layer will then map these down to an embedding_dim-dimensional space. The LSTM takes this sequence of embeddings and iterates over it, fielding an output vector of length hidden_dim. The final linear layer acts as a classifier; applying log_softmax() to the output of the final layer converts the output into a normalized set of estimated probabilities that a given word maps to a given tag."
      ],
      "metadata": {
        "id": "njP47STTcVMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMTagger(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
        "        super(LSTMTagger, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.word_embeddings = torch.nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
        "        # with dimensionality hidden_dim.\n",
        "        self.lstm = torch.nn.LSTM(embedding_dim, hidden_dim)\n",
        "\n",
        "        # The linear layer that maps from hidden state space to tag space\n",
        "        self.hidden2tag = torch.nn.Linear(hidden_dim, tagset_size)\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        embeds = self.word_embeddings(sentence)\n",
        "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
        "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
        "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
        "        return tag_scores"
      ],
      "metadata": {
        "id": "AZAdN_dKcVMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pooling + BatchNorm + Dropout"
      ],
      "metadata": {
        "id": "A4IX-ZgqcVME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_tensor = torch.rand(1, 6, 6)\n",
        "print(my_tensor)\n",
        "\n",
        "maxpool_layer = torch.nn.MaxPool2d(3)\n",
        "print(maxpool_layer(my_tensor))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-28T01:50:53.707695Z",
          "iopub.execute_input": "2023-12-28T01:50:53.709567Z",
          "iopub.status.idle": "2023-12-28T01:50:53.721835Z",
          "shell.execute_reply.started": "2023-12-28T01:50:53.709514Z",
          "shell.execute_reply": "2023-12-28T01:50:53.72038Z"
        },
        "trusted": true,
        "id": "C-Wol94fcVME",
        "outputId": "56fedcd8-a198-44b6-d0aa-3cf9de0e2b05"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "tensor([[[0.9154, 0.1099, 0.0817, 0.9214, 0.0138, 0.5309],\n         [0.5636, 0.2406, 0.4650, 0.9344, 0.7706, 0.7663],\n         [0.6355, 0.6535, 0.9984, 0.7862, 0.3423, 0.3433],\n         [0.4761, 0.4214, 0.9434, 0.0538, 0.2010, 0.5654],\n         [0.7186, 0.6959, 0.3769, 0.4089, 0.8383, 0.1977],\n         [0.4577, 0.5526, 0.2973, 0.4424, 0.1070, 0.6613]]])\ntensor([[[0.9984, 0.9344],\n         [0.9434, 0.8383]]])\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_tensor = torch.rand(1, 4, 4) * 20 + 5\n",
        "print(my_tensor)\n",
        "\n",
        "print(my_tensor.mean())\n",
        "\n",
        "norm_layer = torch.nn.BatchNorm1d(4)\n",
        "normed_tensor = norm_layer(my_tensor)\n",
        "print(normed_tensor)\n",
        "\n",
        "print(normed_tensor.mean())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-28T01:51:55.349859Z",
          "iopub.execute_input": "2023-12-28T01:51:55.350292Z",
          "iopub.status.idle": "2023-12-28T01:51:55.367543Z",
          "shell.execute_reply.started": "2023-12-28T01:51:55.350262Z",
          "shell.execute_reply": "2023-12-28T01:51:55.365739Z"
        },
        "trusted": true,
        "id": "0Ofx-ErrcVMF",
        "outputId": "aed0ddb9-ffee-4a51-bdc5-e80101a8270d"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "tensor([[[15.7163, 16.0728, 10.8773, 23.0611],\n         [ 7.4773, 22.2312, 24.3448, 24.6766],\n         [10.9640, 13.6779, 23.6286, 21.9696],\n         [ 8.5672, 13.6959, 23.3365, 20.3197]]])\ntensor(17.5386)\ntensor([[[-0.1648, -0.0827, -1.2790,  1.5265],\n         [-1.7169,  0.3585,  0.6558,  0.7025],\n         [-1.2310, -0.7245,  1.1325,  0.8229],\n         [-1.3768, -0.4844,  1.1931,  0.6681]]],\n       grad_fn=<NativeBatchNormBackward0>)\ntensor(8.9407e-08, grad_fn=<MeanBackward0>)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_tensor = torch.rand(1, 4, 4)\n",
        "print(my_tensor)\n",
        "dropout = torch.nn.Dropout(p=0.4)\n",
        "print(dropout(my_tensor))\n",
        "print(dropout(my_tensor))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-28T01:53:30.065535Z",
          "iopub.execute_input": "2023-12-28T01:53:30.066017Z",
          "iopub.status.idle": "2023-12-28T01:53:30.08071Z",
          "shell.execute_reply.started": "2023-12-28T01:53:30.065983Z",
          "shell.execute_reply": "2023-12-28T01:53:30.079303Z"
        },
        "trusted": true,
        "id": "q7Kf6yvVcVMF",
        "outputId": "26d7b5b3-e9e1-4a89-b14d-c3193287a065"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "tensor([[[0.9990, 0.5716, 0.7154, 0.7757],\n         [0.4983, 0.9120, 0.9467, 0.1978],\n         [0.3957, 0.2455, 0.4039, 0.3528],\n         [0.9801, 0.8895, 0.7989, 0.4342]]])\ntensor([[[0.0000, 0.9527, 1.1923, 0.0000],\n         [0.8305, 0.0000, 1.5778, 0.3297],\n         [0.0000, 0.4091, 0.6732, 0.5880],\n         [1.6335, 1.4824, 0.0000, 0.7236]]])\ntensor([[[0.0000, 0.9527, 1.1923, 1.2928],\n         [0.0000, 1.5200, 1.5778, 0.3297],\n         [0.6596, 0.4091, 0.6732, 0.5880],\n         [0.0000, 0.0000, 0.0000, 0.7236]]])\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.no_grad() can also be used as a function or method decorato\n",
        "\n",
        "def add_tensors1(x, y):\n",
        "    return x + y\n",
        "\n",
        "@torch.no_grad()\n",
        "def add_tensors2(x, y):\n",
        "    return x + y\n",
        "\n",
        "\n",
        "a = torch.ones(2, 3, requires_grad=True) * 2\n",
        "b = torch.ones(2, 3, requires_grad=True) * 3\n",
        "\n",
        "c1 = add_tensors1(a, b)\n",
        "print(c1)\n",
        "\n",
        "c2 = add_tensors2(a, b)\n",
        "print(c2)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-27T03:57:53.124282Z",
          "iopub.execute_input": "2023-12-27T03:57:53.124713Z",
          "iopub.status.idle": "2023-12-27T03:57:53.13753Z",
          "shell.execute_reply.started": "2023-12-27T03:57:53.124682Z",
          "shell.execute_reply": "2023-12-27T03:57:53.136005Z"
        },
        "trusted": true,
        "id": "_E_CS97wcVMG",
        "outputId": "4e5a4c09-9da3-4825-ad0d-40556b375037"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "tensor([[5., 5., 5.],\n        [5., 5., 5.]], grad_fn=<AddBackward0>)\ntensor([[5., 5., 5.],\n        [5., 5., 5.]])\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import torch\n",
        "import math\n",
        "\n",
        "\n",
        "dtype = torch.float\n",
        "device = torch.device(\"cpu\")\n",
        "# device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
        "\n",
        "# Create random input and output data\n",
        "x = torch.linspace(-math.pi, math.pi, 10, device=device, dtype=dtype)\n",
        "y = torch.sin(x)\n",
        "\n",
        "# Randomly initialize weights\n",
        "a = torch.randn((), device=device, dtype=dtype)\n",
        "b = torch.randn((), device=device, dtype=dtype)\n",
        "c = torch.randn((), device=device, dtype=dtype)\n",
        "d = torch.randn((), device=device, dtype=dtype)\n",
        "\n",
        "learning_rate = 1e-6\n",
        "for t in range(100):\n",
        "    # Forward pass: compute predicted y\n",
        "    y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
        "\n",
        "    # Compute and print loss\n",
        "    loss = (y_pred - y).pow(2).sum().item()\n",
        "    if t % 100 == 0:\n",
        "        print(t, loss)\n",
        "\n",
        "    # Backprop to compute gradients of a, b, c, d with respect to loss\n",
        "    grad_y_pred = 2.0 * (y_pred - y)\n",
        "    grad_a = grad_y_pred.sum()\n",
        "    grad_b = (grad_y_pred * x).sum()\n",
        "    grad_c = (grad_y_pred * x ** 2).sum()\n",
        "    grad_d = (grad_y_pred * x ** 3).sum()\n",
        "\n",
        "    # Update weights using gradient descent\n",
        "    a -= learning_rate * grad_a\n",
        "    b -= learning_rate * grad_b\n",
        "    c -= learning_rate * grad_c\n",
        "    d -= learning_rate * grad_d\n",
        "\n",
        "\n",
        "print(f'Result: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Use autograd to compute the backward pass. This call will compute the\n",
        "    # gradient of loss with respect to all Tensors with requires_grad=True.\n",
        "    # After this call a.grad, b.grad. c.grad and d.grad will be Tensors holding\n",
        "    # the gradient of the loss with respect to a, b, c, d respectively.\n",
        "    loss.backward()\n",
        "\n",
        "    # Manually update weights using gradient descent. Wrap in torch.no_grad()\n",
        "    # because weights have requires_grad=True, but we don't need to track this\n",
        "    # in autograd.\n",
        "    with torch.no_grad():\n",
        "        a -= learning_rate * a.grad\n",
        "        b -= learning_rate * b.grad\n",
        "        c -= learning_rate * c.grad\n",
        "        d -= learning_rate * d.grad\n",
        "\n",
        "        # Manually zero the gradients after updating weights\n",
        "        a.grad = None\n",
        "        b.grad = None\n",
        "        c.grad = None\n",
        "        d.grad = None\n",
        "\n",
        "print(f'Result: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-29T07:50:10.415106Z",
          "iopub.status.idle": "2023-11-29T07:50:10.41547Z",
          "shell.execute_reply.started": "2023-11-29T07:50:10.415285Z",
          "shell.execute_reply": "2023-11-29T07:50:10.415301Z"
        },
        "trusted": true,
        "id": "yT985A_UcVMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we tried to call y.backward() now, we’d get a runtime error and a message that gradients can only be implicitly computed for scalar outputs. For a multi-dimensional output, autograd expects us to provide gradients for those three outputs that it can multiply into the Jacobian:\n",
        "\n",
        "\n",
        "(Note that the output gradients are all related to powers of two - which we’d expect from a repeated doubling operation.)"
      ],
      "metadata": {
        "id": "iSfREEw0cVMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(3, requires_grad=True)\n",
        "\n",
        "y = x * 2\n",
        "while y.data.norm() < 1000:\n",
        "    y = y * 2\n",
        "\n",
        "print(y)\n",
        "\n",
        "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float) # stand-in for gradients\n",
        "y.backward(v)\n",
        "\n",
        "print(x.grad)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-28T01:36:57.785404Z",
          "iopub.execute_input": "2023-12-28T01:36:57.786495Z",
          "iopub.status.idle": "2023-12-28T01:36:57.802798Z",
          "shell.execute_reply.started": "2023-12-28T01:36:57.78645Z",
          "shell.execute_reply": "2023-12-28T01:36:57.801372Z"
        },
        "trusted": true,
        "id": "zhIITVeEcVMS",
        "outputId": "2e8628b8-fe80-46e6-8baf-928ede17d246"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "tensor([  69.0714,  481.0133, 1008.0416], grad_fn=<MulBackward0>)\ntensor([5.1200e+01, 5.1200e+02, 5.1200e-02])\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is an API on autograd that gives you direct access to important differential matrix and vector operations. In particular, it allows you to calculate the Jacobian and the Hessian matrices of a particular function for particular inputs. (The Hessian is like the Jacobian, but expresses all partial second derivatives.) It also provides methods for taking vector products with these matrices.\n",
        "\n",
        "Let’s take the Jacobian of a simple function, evaluated for a 2 single-element inputs:\n",
        "\n",
        "\n",
        "If you look closely, the first output should equal  2*e^x (since the derivative of e^x is e^x), and the second value should be 3.\n",
        "\n",
        "You can, of course, do this with higher-order tensors:"
      ],
      "metadata": {
        "id": "GIuim3WzcVMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def exp_adder(x, y):\n",
        "    return 2 * x.exp() + 3 * y\n",
        "\n",
        "inputs = (torch.rand(3), torch.rand(3)) # arguments for the function\n",
        "print(inputs)\n",
        "torch.autograd.functional.jacobian(exp_adder, inputs)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-28T01:42:42.484975Z",
          "iopub.execute_input": "2023-12-28T01:42:42.486966Z",
          "iopub.status.idle": "2023-12-28T01:42:42.515675Z",
          "shell.execute_reply.started": "2023-12-28T01:42:42.4869Z",
          "shell.execute_reply": "2023-12-28T01:42:42.514274Z"
        },
        "trusted": true,
        "id": "hYNSmGOecVMT",
        "outputId": "91498655-9154-46dc-9ac7-9e280ecec45c"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "(tensor([0.1351, 0.8873, 0.0998]), tensor([0.2679, 0.2757, 0.8676]))\n",
          "output_type": "stream"
        },
        {
          "execution_count": 4,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(tensor([[2.2892, 0.0000, 0.0000],\n         [0.0000, 4.8572, 0.0000],\n         [0.0000, 0.0000, 2.2098]]),\n tensor([[3., 0., 0.],\n         [0., 3., 0.],\n         [0., 0., 3.]]))"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The torch.autograd.functional.hessian() method works identically (assuming your function is twice differentiable), but returns a matrix of all second derivatives.\n",
        "\n",
        "There is also a function to directly compute the vector-Jacobian product, if you provide the vector:"
      ],
      "metadata": {
        "id": "GHqGJzr5cVMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def do_some_doubling(x):\n",
        "    y = x * 2\n",
        "    while y.data.norm() < 1000:\n",
        "        y = y * 2\n",
        "    return y\n",
        "\n",
        "inputs = torch.randn(3)\n",
        "my_gradients = torch.tensor([0.1, 1.0, 0.0001])\n",
        "torch.autograd.functional.vjp(do_some_doubling, inputs, v=my_gradients)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-28T01:43:52.185144Z",
          "iopub.execute_input": "2023-12-28T01:43:52.185617Z",
          "iopub.status.idle": "2023-12-28T01:43:52.198638Z",
          "shell.execute_reply.started": "2023-12-28T01:43:52.185584Z",
          "shell.execute_reply": "2023-12-28T01:43:52.196709Z"
        },
        "trusted": true,
        "id": "y54s2gIhcVMU",
        "outputId": "bc762b1a-562a-41ef-e2fd-caa63e7131ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 5,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(tensor([ 819.0781, -173.8911, -908.0206]),\n tensor([5.1200e+01, 5.1200e+02, 5.1200e-02]))"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import math\n",
        "\n",
        "a = torch.linspace(0., 2* math.pi, steps=5, requires_grad=True)\n",
        "print(\"a : \",a)\n",
        "b = torch.sin(a)\n",
        "print(\"sin(a) : \",b)\n",
        "plt.plot(a.detach(), b.detach())\n",
        "c = 2 * b\n",
        "print(\"c : \",c)\n",
        "d = c + 1\n",
        "print(\"d : \",d)\n",
        "out = d.sum()\n",
        "print(\"out : \",out)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-27T03:28:37.982595Z",
          "iopub.execute_input": "2023-12-27T03:28:37.983619Z",
          "iopub.status.idle": "2023-12-27T03:28:38.305772Z",
          "shell.execute_reply.started": "2023-12-27T03:28:37.98358Z",
          "shell.execute_reply": "2023-12-27T03:28:38.304442Z"
        },
        "trusted": true,
        "id": "PIlp61cbcVMU",
        "outputId": "ccc4fe9d-c8b6-4f44-cbc3-b6125f20ff64"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "a :  tensor([0.0000, 1.5708, 3.1416, 4.7124, 6.2832], requires_grad=True)\nsin(a) :  tensor([ 0.0000e+00,  1.0000e+00, -8.7423e-08, -1.0000e+00,  1.7485e-07],\n       grad_fn=<SinBackward0>)\nc :  tensor([ 0.0000e+00,  2.0000e+00, -1.7485e-07, -2.0000e+00,  3.4969e-07],\n       grad_fn=<MulBackward0>)\nd :  tensor([ 1.0000,  3.0000,  1.0000, -1.0000,  1.0000], grad_fn=<AddBackward0>)\nout :  tensor(5.0000, grad_fn=<SumBackward0>)\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 640x480 with 1 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each grad_fn stored with our tensors allows you to walk the computation all the way back to its inputs with its next_functions property. We can see below that drilling down on this property on d shows us the gradient functions for all the prior tensors. Note that a.grad_fn is reported as None, indicating that this was an input to the function with no history of its own."
      ],
      "metadata": {
        "id": "g95GAe7ccVMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('d: ',d.grad_fn)\n",
        "print(\"walking along computation graph for grad calculation : \")\n",
        "print(d.grad_fn.next_functions)\n",
        "print(d.grad_fn.next_functions[0][0].next_functions)\n",
        "print(d.grad_fn.next_functions[0][0].next_functions[0][0].next_functions)\n",
        "print(d.grad_fn.next_functions[0][0].next_functions[0][0].next_functions[0][0].next_functions)\n",
        "print('c: ',c.grad_fn)\n",
        "print('b: ',b.grad_fn)\n",
        "print('a: ',a.grad_fn)\n",
        "# calculating grad\n",
        "print(\"before grad calculation out : \",out)\n",
        "out.backward()\n",
        "print(\"after grad calculation out : \",out)\n",
        "print(\"a.grad  : \",a.grad)\n",
        "plt.plot(a.detach(), a.grad.detach())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-27T03:28:44.390893Z",
          "iopub.execute_input": "2023-12-27T03:28:44.391441Z",
          "iopub.status.idle": "2023-12-27T03:28:44.642697Z",
          "shell.execute_reply.started": "2023-12-27T03:28:44.391404Z",
          "shell.execute_reply": "2023-12-27T03:28:44.641123Z"
        },
        "trusted": true,
        "id": "IHk-36h0cVMV",
        "outputId": "9fd55721-8b01-463a-fd15-726aaf9bd138"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "d:  <AddBackward0 object at 0x7c847c5e85e0>\nwalking along computation graph for grad calculation : \n((<MulBackward0 object at 0x7c847c5e9330>, 0), (None, 0))\n((<SinBackward0 object at 0x7c847c5e9870>, 0), (None, 0))\n((<AccumulateGrad object at 0x7c847c5e85b0>, 0),)\n()\nc:  <MulBackward0 object at 0x7c847c5e85b0>\nb:  <SinBackward0 object at 0x7c847c5e85e0>\na:  None\nbefore grad calculation out :  tensor(5.0000, grad_fn=<SumBackward0>)\nafter grad calculation out :  tensor(5.0000, grad_fn=<SumBackward0>)\na.grad  :  tensor([ 2.0000e+00, -8.7423e-08, -2.0000e+00,  2.3850e-08,  2.0000e+00])\n",
          "output_type": "stream"
        },
        {
          "execution_count": 52,
          "output_type": "execute_result",
          "data": {
            "text/plain": "[<matplotlib.lines.Line2D at 0x7c847c5f3910>]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 640x480 with 1 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nPs8SC7IcVMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(epoch_index, tb_writer):\n",
        "    running_loss = 0.\n",
        "    last_loss = 0.\n",
        "\n",
        "    # Here, we use enumerate(training_loader) instead of\n",
        "    # iter(training_loader) so that we can track the batch\n",
        "    # index and do some intra-epoch reporting\n",
        "    for i, data in enumerate(training_loader):\n",
        "        # Every data instance is an input + label pair\n",
        "        inputs, labels = data\n",
        "\n",
        "        # Zero your gradients for every batch!\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Make predictions for this batch\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Compute the loss and its gradients\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        # Adjust learning weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # Gather data and report\n",
        "        running_loss += loss.item()\n",
        "        if i % 1000 == 999:\n",
        "            last_loss = running_loss / 1000 # loss per batch\n",
        "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
        "            tb_x = epoch_index * len(training_loader) + i + 1\n",
        "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
        "            running_loss = 0.\n",
        "\n",
        "    return last_loss\n",
        "\n",
        "\n",
        "\n",
        "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
        "epoch_number = 0\n",
        "\n",
        "EPOCHS = 5\n",
        "\n",
        "best_vloss = 1_000_000.\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print('EPOCH {}:'.format(epoch_number + 1))\n",
        "\n",
        "    # Make sure gradient tracking is on, and do a pass over the data\n",
        "    model.train(True)\n",
        "    avg_loss = train_one_epoch(epoch_number, writer)\n",
        "\n",
        "\n",
        "    running_vloss = 0.0\n",
        "    # Set the model to evaluation mode, disabling dropout and using population\n",
        "    # statistics for batch normalization.\n",
        "    model.eval()\n",
        "\n",
        "    # Disable gradient computation and reduce memory consumption.\n",
        "    with torch.no_grad():\n",
        "        for i, vdata in enumerate(validation_loader):\n",
        "            vinputs, vlabels = vdata\n",
        "            voutputs = model(vinputs)\n",
        "            vloss = loss_fn(voutputs, vlabels)\n",
        "            running_vloss += vloss\n",
        "\n",
        "    avg_vloss = running_vloss / (i + 1)\n",
        "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
        "\n",
        "    # Log the running loss averaged per batch\n",
        "    # for both training and validation\n",
        "    writer.add_scalars('Training vs. Validation Loss',\n",
        "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
        "                    epoch_number + 1)\n",
        "    writer.flush()\n",
        "\n",
        "    # Track best performance, and save the model's state\n",
        "    if avg_vloss < best_vloss:\n",
        "        best_vloss = avg_vloss\n",
        "        model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "\n",
        "    epoch_number += 1"
      ],
      "metadata": {
        "id": "Ks90S6kycVMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import math\n",
        "\n",
        "\n",
        "class Polynomial3(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        In the constructor we instantiate four parameters and assign them as\n",
        "        member parameters.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.a = torch.nn.Parameter(torch.randn(()))\n",
        "        self.b = torch.nn.Parameter(torch.randn(()))\n",
        "        self.c = torch.nn.Parameter(torch.randn(()))\n",
        "        self.d = torch.nn.Parameter(torch.randn(()))\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        In the forward function we accept a Tensor of input data and we must return\n",
        "        a Tensor of output data. We can use Modules defined in the constructor as\n",
        "        well as arbitrary operators on Tensors.\n",
        "        \"\"\"\n",
        "        return self.a + self.b * x + self.c * x ** 2 + self.d * x ** 3\n",
        "\n",
        "    def string(self):\n",
        "        \"\"\"\n",
        "        Just like any class in Python, you can also define custom method on PyTorch modules\n",
        "        \"\"\"\n",
        "        return f'y = {self.a.item()} + {self.b.item()} x + {self.c.item()} x^2 + {self.d.item()} x^3'\n",
        "\n",
        "\n",
        "# Create Tensors to hold input and outputs.\n",
        "x = torch.linspace(-math.pi, math.pi, 2000)\n",
        "y = torch.sin(x)\n",
        "\n",
        "# Construct our model by instantiating the class defined above\n",
        "model = Polynomial3()\n",
        "\n",
        "# Construct our loss function and an Optimizer. The call to model.parameters()\n",
        "# in the SGD constructor will contain the learnable parameters (defined\n",
        "# with torch.nn.Parameter) which are members of the model.\n",
        "criterion = torch.nn.MSELoss(reduction='sum')\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-6)\n",
        "for t in range(2000):\n",
        "    # Forward pass: Compute predicted y by passing x to the model\n",
        "    y_pred = model(x)\n",
        "\n",
        "    # Compute and print loss\n",
        "    loss = criterion(y_pred, y)\n",
        "    if t % 100 == 0:\n",
        "        print(t, loss.item())\n",
        "\n",
        "    # Zero gradients, perform a backward pass, and update the weights.\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(f'Result: {model.string()}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-28T02:12:09.174509Z",
          "iopub.execute_input": "2023-12-28T02:12:09.175027Z",
          "iopub.status.idle": "2023-12-28T02:12:09.830603Z",
          "shell.execute_reply.started": "2023-12-28T02:12:09.174988Z",
          "shell.execute_reply": "2023-12-28T02:12:09.82934Z"
        },
        "trusted": true,
        "id": "46L88034cVMW",
        "outputId": "a5ca3778-6e8b-40e2-aefc-9955e43c40af"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "0 1067579.625\n100 1314.68603515625\n200 872.380859375\n300 579.8905029296875\n400 386.4690856933594\n500 258.5603942871094\n600 173.97476196289062\n700 118.03816223144531\n800 81.04708862304688\n900 56.584510803222656\n1000 40.407020568847656\n1100 29.70855712890625\n1200 22.63350486755371\n1300 17.954547882080078\n1400 14.860237121582031\n1500 12.813790321350098\n1600 11.460406303405762\n1700 10.56534481048584\n1800 9.973381042480469\n1900 9.5818510055542\nResult: y = 0.0014096597442403436 + 0.8348725438117981 x + -0.00024319066142197698 x^2 + -0.09021981060504913 x^3\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import torch\n",
        "import math\n",
        "\n",
        "\n",
        "class DynamicNet(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        In the constructor we instantiate five parameters and assign them as members.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.a = torch.nn.Parameter(torch.randn(()))\n",
        "        self.b = torch.nn.Parameter(torch.randn(()))\n",
        "        self.c = torch.nn.Parameter(torch.randn(()))\n",
        "        self.d = torch.nn.Parameter(torch.randn(()))\n",
        "        self.e = torch.nn.Parameter(torch.randn(()))\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        For the forward pass of the model, we randomly choose either 4, 5\n",
        "        and reuse the e parameter to compute the contribution of these orders.\n",
        "\n",
        "        Since each forward pass builds a dynamic computation graph, we can use normal\n",
        "        Python control-flow operators like loops or conditional statements when\n",
        "        defining the forward pass of the model.\n",
        "\n",
        "        Here we also see that it is perfectly safe to reuse the same parameter many\n",
        "        times when defining a computational graph.\n",
        "        \"\"\"\n",
        "        y = self.a + self.b * x + self.c * x ** 2 + self.d * x ** 3\n",
        "        for exp in range(4, random.randint(4, 6)):\n",
        "            y = y + self.e * x ** exp\n",
        "        return y\n",
        "\n",
        "    def string(self):\n",
        "        \"\"\"\n",
        "        Just like any class in Python, you can also define custom method on PyTorch modules\n",
        "        \"\"\"\n",
        "        return f'y = {self.a.item()} + {self.b.item()} x + {self.c.item()} x^2 + {self.d.item()} x^3 + {self.e.item()} x^4 ? + {self.e.item()} x^5 ?'\n",
        "\n",
        "\n",
        "# Create Tensors to hold input and outputs.\n",
        "x = torch.linspace(-math.pi, math.pi, 20)\n",
        "y = torch.sin(x)\n",
        "\n",
        "# Construct our model by instantiating the class defined above\n",
        "model = DynamicNet()\n",
        "\n",
        "# Construct our loss function and an Optimizer. Training this strange model with\n",
        "# vanilla stochastic gradient descent is tough, so we use momentum\n",
        "criterion = torch.nn.MSELoss(reduction='sum')\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-8, momentum=0.9)\n",
        "for t in range(300):\n",
        "    # Forward pass: Compute predicted y by passing x to the model\n",
        "    y_pred = model(x)\n",
        "\n",
        "    # Compute and print loss\n",
        "    loss = criterion(y_pred, y)\n",
        "    if t % 20 == 0:\n",
        "        print(t, loss.item())\n",
        "\n",
        "    # Zero gradients, perform a backward pass, and update the weights.\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(f'Result: {model.string()}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-28T02:16:28.569425Z",
          "iopub.execute_input": "2023-12-28T02:16:28.570035Z",
          "iopub.status.idle": "2023-12-28T02:16:28.707987Z",
          "shell.execute_reply.started": "2023-12-28T02:16:28.569993Z",
          "shell.execute_reply": "2023-12-28T02:16:28.706871Z"
        },
        "trusted": true,
        "id": "dZkMmwOXcVMW",
        "outputId": "5cc55ca2-2ea2-4c64-afcb-0a35a0674c20"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "0 2705.714599609375\n20 2649.596435546875\n40 2212.77294921875\n60 1027.913330078125\n80 2463.24609375\n100 2392.26220703125\n120 2043.373779296875\n140 2002.381591796875\n160 988.0462036132812\n180 1926.952880859375\n200 940.7538452148438\n220 932.4345703125\n240 1812.5201416015625\n260 922.9461669921875\n280 1738.956787109375\nResult: y = 1.9864966869354248 + -2.382695436477661 x + 0.30508556962013245 x^2 + -0.28453633189201355 x^3 + 0.04388752579689026 x^4 ? + 0.04388752579689026 x^5 ?\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "7QqviMkDcVMX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}