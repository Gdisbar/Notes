{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791048ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "464f2461",
   "metadata": {},
   "source": [
    "### sklearn.neighbors.KNeighborsClassifier\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3755190c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ..utils.fixes import _mode\n",
    "from ..utils.extmath import weighted_mode\n",
    "from ..utils.validation import _is_arraylike, _num_samples\n",
    "\n",
    "import warnings\n",
    "from ._base import _check_weights, _get_weights\n",
    "from ._base import NeighborsBase, KNeighborsMixin, RadiusNeighborsMixin\n",
    "from ..base import ClassifierMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fcfb04",
   "metadata": {},
   "source": [
    "\n",
    "### Parameters\n",
    "\n",
    "    n_neighbors : int, default=5\n",
    "        Number of neighbors to use by default for :meth:`kneighbors` queries.\n",
    "    weights : {'uniform', 'distance'} or callable, default='uniform'\n",
    "        Weight function used in prediction.  Possible values:\n",
    "        - 'uniform' : uniform weights.  All points in each neighborhood\n",
    "          are weighted equally.\n",
    "        - 'distance' : weight points by the inverse of their distance.\n",
    "          in this case, closer neighbors of a query point will have a\n",
    "          greater influence than neighbors which are further away.\n",
    "        - [callable] : a user-defined function which accepts an\n",
    "          array of distances, and returns an array of the same shape\n",
    "          containing the weights.\n",
    "    algorithm : {'auto', 'ball_tree', 'kd_tree', 'brute'}, default='auto'\n",
    "        Algorithm used to compute the nearest neighbors:\n",
    "        - 'ball_tree' will use :class:`BallTree`\n",
    "        - 'kd_tree' will use :class:`KDTree`\n",
    "        - 'brute' will use a brute-force search.\n",
    "        - 'auto' will attempt to decide the most appropriate algorithm\n",
    "          based on the values passed to :meth:`fit` method.\n",
    "        Note: fitting on sparse input will override the setting of\n",
    "        this parameter, using brute force.\n",
    "    leaf_size : int, default=30\n",
    "        Leaf size passed to BallTree or KDTree.  This can affect the\n",
    "        speed of the construction and query, as well as the memory\n",
    "        required to store the tree.  The optimal value depends on the\n",
    "        nature of the problem.\n",
    "    p : int, default=2\n",
    "        Power parameter for the Minkowski metric. When p = 1, this is\n",
    "        equivalent to using manhattan_distance (l1), and euclidean_distance\n",
    "        (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.\n",
    "    metric : str or callable, default='minkowski'\n",
    "        Metric to use for distance computation. Default is \"minkowski\", which\n",
    "        results in the standard Euclidean distance when p = 2. See the\n",
    "       \n",
    "        If metric is \"precomputed\", X is assumed to be a distance matrix and\n",
    "        must be square during fit. X may be a :term:`sparse graph`, in which\n",
    "        case only \"nonzero\" elements may be considered neighbors.\n",
    "        If metric is a callable function, it takes two arrays representing 1D\n",
    "        vectors as inputs and must return one value indicating the distance\n",
    "        between those vectors. This works for Scipy's metrics, but is less\n",
    "        efficient than passing the metric name as a string.\n",
    "    metric_params : dict, default=None\n",
    "        Additional keyword arguments for the metric function.\n",
    "   \n",
    "### Attributes\n",
    "    \n",
    "    classes_ : array of shape (n_classes,)\n",
    "        Class labels known to the classifier\n",
    "    effective_metric_ : str or callble\n",
    "        The distance metric used. It will be same as the `metric` parameter\n",
    "        or a synonym of it, e.g. 'euclidean' if the `metric` parameter set to\n",
    "        'minkowski' and `p` parameter set to 2.\n",
    "    effective_metric_params_ : dict\n",
    "        Additional keyword arguments for the metric function. For most metrics\n",
    "        will be same with `metric_params` parameter, but may also contain the\n",
    "        `p` parameter value if the `effective_metric_` attribute is set to\n",
    "        'minkowski'.\n",
    "    n_features_in_ : int\n",
    "        Number of features seen during :term:`fit`.\n",
    "        .. versionadded:: 0.24\n",
    "    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
    "        Names of features seen during :term:`fit`. Defined only when `X`\n",
    "        has feature names that are all strings.\n",
    "        .. versionadded:: 1.0\n",
    "    n_samples_fit_ : int\n",
    "        Number of samples in the fitted data.\n",
    "    outputs_2d_ : bool\n",
    "        False when `y`'s shape is (n_samples, ) or (n_samples, 1) during fit\n",
    "        otherwise True.\n",
    "### See Also\n",
    "\n",
    "    RadiusNeighborsClassifier: Classifier based on neighbors within a fixed radius.\n",
    "    KNeighborsRegressor: Regression based on k-nearest neighbors.\n",
    "    RadiusNeighborsRegressor: Regression based on neighbors within a fixed radius.\n",
    "    NearestNeighbors: Unsupervised learner for implementing neighbor searches.\n",
    "    \n",
    "    .. warning::\n",
    "       Regarding the Nearest Neighbors algorithms, if it is found that two\n",
    "       neighbors, neighbor `k+1` and `k`, have identical distances\n",
    "       but different labels, the results will depend on the ordering of the\n",
    "       training data.\n",
    "  \n",
    "  \n",
    "  \n",
    "**fit()**:\n",
    "\n",
    "     Parameters\n",
    "    ----------\n",
    "    X : {array-like, sparse matrix} of shape (n_samples, n_features) or \\\n",
    "            (n_samples, n_samples) if metric='precomputed'\n",
    "        Training data.\n",
    "    y : {array-like, sparse matrix} of shape (n_samples,) or \\\n",
    "            (n_samples, n_outputs)\n",
    "        Target values.\n",
    "    \n",
    "                    \n",
    "**predict()**:\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array-like of shape (n_queries, n_features), \\\n",
    "            or (n_queries, n_indexed) if metric == 'precomputed'\n",
    "        Test samples.\n",
    "    Returns\n",
    "    -------\n",
    "    y : ndarray of shape (n_queries,) or (n_queries, n_outputs)\n",
    "        Class labels for each data sample.\n",
    " **predict_proba()**:\n",
    " \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array-like of shape (n_queries, n_features), \\\n",
    "            or (n_queries, n_indexed) if metric == 'precomputed'\n",
    "        Test samples.\n",
    "    Returns\n",
    "    -------\n",
    "    p : ndarray of shape (n_queries, n_classes), or a list of n_outputs \\\n",
    "            of such arrays if n_outputs > 1.\n",
    "        The class probabilities of the input samples. Classes are ordered\n",
    "        by lexicographic order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0742422a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNeighborsClassifier(KNeighborsMixin, ClassifierMixin, NeighborsBase):\n",
    "    \"\"\"Classifier implementing the k-nearest neighbors vote.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(...):\n",
    "        super().__init__(...)\n",
    "        self.weights = weights\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit the k-nearest neighbors classifier from the training dataset.\n",
    "        \"\"\"\n",
    "        self.weights = _check_weights(self.weights)\n",
    "\n",
    "        return self._fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict the class labels for the provided data.\n",
    "        \n",
    "        \"\"\"\n",
    "        1. for \"uniform\" weights we don''t need return_distance from self.kneighbors(X)\n",
    "        2. store number of classs & make output 2D (shape=(-1,1))\n",
    "        3. initalize y_pred (shape=(sample_length, class_length))\n",
    "        4. for each classes calculated weighted mode (if weight present) + store them\n",
    "            (use np.ravel() to make proper shape (-1,1 or 2D))\n",
    "        \n",
    "        return y_pred\n",
    "        \n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Return probability estimates for the test data X.\n",
    "        \"\"\"\n",
    "        1. first 2 steps are same + if weights are none initalize them with ones\n",
    "        2. normalize votes into real [0,1] probabilities + take extra care of dimensions\n",
    "           as here we need to loop through n_neighbors to get proba_k[all_rows,idx]  \n",
    "        3. take care of output dimensions\n",
    "        return probabilities\n",
    "\n",
    "    def _more_tags(self):\n",
    "        return {\"multilabel\": True}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd0f6db",
   "metadata": {},
   "source": [
    "\n",
    "### Parameters\n",
    "\n",
    "    radius : float, default=1.0\n",
    "        Range of parameter space to use by default for :meth:`radius_neighbors`\n",
    "        queries.\n",
    "    \n",
    "    outlier_label : {manual label, 'most_frequent'}, default=None\n",
    "        Label for outlier samples (samples with no neighbors in given radius).\n",
    "        - manual label: str or int label (should be the same type as y)\n",
    "          or list of manual labels if multi-output is used.\n",
    "        - 'most_frequent' : assign the most frequent label of y to outliers.\n",
    "        - None : when any outlier is detected, ValueError will be raised.   \n",
    "    **kwargs : dict\n",
    "        Additional keyword arguments passed to the constructor.\n",
    "        .. deprecated:: 1.0\n",
    "            The RadiusNeighborsClassifier class will not longer accept extra\n",
    "            keyword parameters in 1.2 since they are unused.\n",
    "### Attributes\n",
    "\n",
    "    outlier_label_ : int or array-like of shape (n_class,)\n",
    "        Label which is given for outlier samples (samples with no neighbors\n",
    "        on given radius).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473aa7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RadiusNeighborsClassifier(RadiusNeighborsMixin, ClassifierMixin, NeighborsBase):\n",
    "    \"\"\"Classifier implementing a vote among neighbors within a given radius.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(...):\n",
    "        # TODO: Remove in v1.2\n",
    "        if len(kwargs) > 0:\n",
    "            warnings.warn(...)\n",
    "        super().__init__(...)\n",
    "        self.weights = weights\n",
    "        self.outlier_label = outlier_label\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit the radius neighbors classifier from the training dataset.\n",
    "        \"\"\"\n",
    "        self.weights = _check_weights(self.weights)\n",
    "        self._fit(X, y)\n",
    "        1. get classes & y\n",
    "        2. some hyperparameter checking\n",
    "            1. check if outlier_label is None or \n",
    "            2. elif \"most_frequent\" use bincount on _y[:,k] to get outlier_label\n",
    "            3. else outlier_label depends on number of classes , check for consistency\n",
    "                in output length & instances\n",
    "        3. for each classes & oulier_label check dtype & scalar + store outlier_label\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict the class labels for the provided data.\n",
    "        \"\"\"\n",
    "\n",
    "        probs = self.predict_proba(X)\n",
    "        1. store classes, check if output is 2D or not\n",
    "        2. initalize y_pred calculate value take max probability index for each class\n",
    "           if there is any non_zero for outlier_zero_probs take into account\n",
    "        3. a dimension check to amke sure it''s 2D , use ravel()\n",
    "        \n",
    "        return y_pred\n",
    "\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Return probability estimates for the test data X.\n",
    "        \"\"\"\n",
    "\n",
    "        n_queries = _num_samples(X)\n",
    "        neigh_dist, neigh_ind = self.radius_neighbors(X)\n",
    "        \n",
    "        1. get outlier_mask , inliers(i.e non-outlier_mask),classes,y\n",
    "        2. check if output is 2D , outlier_label_ is None & weights\n",
    "        3. calculate pred_labels,proba_k,prob_inl for each classes\n",
    "        4. if weight is None get proba_inl[i,:] using bincount on inliers\n",
    "        5. normalize above calculated probability of proba_k & append in probabilities\n",
    "        6. check output dimensions\n",
    "        \n",
    "        return probabilities\n",
    "        \n",
    "\n",
    "    def _more_tags(self):\n",
    "        return {\"multilabel\": True}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daaa3f1a",
   "metadata": {},
   "source": [
    "## Implementation from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04424e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26b6c7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load iris data and store in dataframe\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17169c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate X and y data\n",
    "\n",
    "X = df.drop('target', axis=1)\n",
    "y = df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d03bdb8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6999999999999993"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate distance between two points\n",
    "\n",
    "def minkowski_distance(a, b, p=1):\n",
    "    \n",
    "    # Store the number of dimensions\n",
    "    dim = len(a)\n",
    "    \n",
    "    # Set initial distance to 0\n",
    "    distance = 0\n",
    "    \n",
    "    # Calculate minkowski distance using parameter p\n",
    "    for d in range(dim):\n",
    "        distance += abs(a[d] - b[d])**p\n",
    "        \n",
    "    distance = distance**(1/p)\n",
    "    \n",
    "    return distance\n",
    "\n",
    "\n",
    "# Test the function\n",
    "\n",
    "minkowski_distance(a=X.iloc[0], b=X.iloc[1], p=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82f91b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dist\n",
       "0   2.7\n",
       "1   2.0\n",
       "2   2.3\n",
       "3   2.1\n",
       "4   2.7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define an arbitrary test point\n",
    "\n",
    "test_pt = [4.8, 2.7, 2.5, 0.7]\n",
    "\n",
    "# Calculate distance between test_pt and all points in X\n",
    "\n",
    "distances = []\n",
    "\n",
    "for i in X.index:\n",
    "    \n",
    "    distances.append(minkowski_distance(test_pt, X.iloc[i]))\n",
    "    \n",
    "df_dists = pd.DataFrame(data=distances, index=X.index, columns=['dist'])\n",
    "df_dists.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8b73c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dist\n",
       "98   1.4\n",
       "57   1.5\n",
       "93   1.7\n",
       "24   1.8\n",
       "30   1.8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the 5 nearest neighbors\n",
    "\n",
    "df_nn = df_dists.sort_values(by=['dist'], axis=0)[:5]\n",
    "df_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83af3ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Create counter object to track the labels\n",
    "\n",
    "counter = Counter(y[df_nn.index])\n",
    "\n",
    "# Get most common label of all the nearest neighbors\n",
    "\n",
    "counter.most_common()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52ba60f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Split the data - 75% train, 25% test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25,\n",
    "                                                   random_state=1)\n",
    "\n",
    "# Scale the X data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b9c34d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 0, 2, 1, 2, 0, 0, 2, 1, 0, 2, 1, 1, 0, 1, 1, 0, 0, 1, 1, 2, 0, 2, 1, 0, 0, 1, 2, 1, 2, 1, 2, 2, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "def knn_predict(X_train, X_test, y_train, y_test, k, p):\n",
    "    \n",
    "    # Counter to help with label voting\n",
    "    from collections import Counter\n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    # Need output of 1 prediction per test data point\n",
    "    y_hat_test = []\n",
    "\n",
    "    for test_point in X_test:\n",
    "        distances = []\n",
    "\n",
    "        for train_point in X_train:\n",
    "            distance = minkowski_distance(test_point, train_point, p=p)\n",
    "            distances.append(distance)\n",
    "        \n",
    "        # Store distances in a dataframe\n",
    "        df_dists = pd.DataFrame(data=distances, columns=['dist'], \n",
    "                                index=y_train.index)\n",
    "        \n",
    "        # Sort distances, and only consider the k closest points\n",
    "        df_nn = df_dists.sort_values(by=['dist'], axis=0)[:k]\n",
    "\n",
    "        # Create counter object to track the labels of k closest neighbors\n",
    "        counter = Counter(y_train[df_nn.index])\n",
    "\n",
    "        # Get most common label of all the nearest neighbors\n",
    "        prediction = counter.most_common()[0][0]\n",
    "        \n",
    "        # Append prediction to output list\n",
    "        y_hat_test.append(prediction)\n",
    "        \n",
    "    return y_hat_test\n",
    "\n",
    "\n",
    "# Make predictions on test dataset\n",
    "y_hat_test = knn_predict(X_train, X_test, y_train, y_test, k=5, p=1)\n",
    "\n",
    "print(y_hat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c754067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "# Get test accuracy score\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8cbf9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn KNN Accuracy: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "# Testing to see results from sklearn.neighbors.KNeighborsClassifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=5, p=1)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_test = clf.predict(X_test)\n",
    "\n",
    "print(f\"Sklearn KNN Accuracy: {accuracy_score(y_test, y_pred_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78464247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Obtain accuracy score varying k from 1 to 99\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for k in range(1,100):\n",
    "    y_hat_test = knn_predict(X_train, X_test, y_train, y_test, k, p=1)\n",
    "    accuracies.append(accuracy_score(y_test, y_hat_test))\n",
    "\n",
    "# Plot the results \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax.plot(range(1,100), accuracies)\n",
    "ax.set_xlabel('# of Nearest Neighbors (k)')\n",
    "ax.set_ylabel('Accuracy (%)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2c76b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.stats import mode\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e94bae48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# K Nearest Neighbors Classification\n",
    "\n",
    "class K_Nearest_Neighbors_Classifier() :\n",
    "\t\n",
    "\tdef __init__( self, K ) :\n",
    "\t\t\n",
    "\t\tself.K = K\n",
    "\t\t\n",
    "\t# Function to store training set\n",
    "\t\t\n",
    "\tdef fit( self, X_train, Y_train ) :\n",
    "\t\t\n",
    "\t\tself.X_train = X_train\n",
    "\t\t\n",
    "\t\tself.Y_train = Y_train\n",
    "\t\t\n",
    "\t\t# no_of_training_examples, no_of_features\n",
    "\t\t\n",
    "\t\tself.m, self.n = X_train.shape\n",
    "\t\n",
    "\t# Function for prediction\n",
    "\t\t\n",
    "\tdef predict( self, X_test ) :\n",
    "\t\t\n",
    "\t\tself.X_test = X_test\n",
    "\t\t\n",
    "\t\t# no_of_test_examples, no_of_features\n",
    "\t\t\n",
    "\t\tself.m_test, self.n = X_test.shape\n",
    "\t\t\n",
    "\t\t# initialize Y_predict\n",
    "\t\t\n",
    "\t\tY_predict = np.zeros( self.m_test )\n",
    "\t\t\n",
    "\t\tfor i in range( self.m_test ) :\n",
    "\t\t\t\n",
    "\t\t\tx = self.X_test[i]\n",
    "\t\t\t\n",
    "\t\t\t# find the K nearest neighbors from current test example\n",
    "\t\t\t\n",
    "\t\t\tneighbors = np.zeros( self.K )\n",
    "\t\t\t\n",
    "\t\t\tneighbors = self.find_neighbors( x )\n",
    "\t\t\t\n",
    "\t\t\t# most frequent class in K neighbors\n",
    "\t\t\t\n",
    "\t\t\tY_predict[i] = mode( neighbors )[0][0]\t\n",
    "\t\t\t\n",
    "\t\treturn Y_predict\n",
    "\t\n",
    "\t# Function to find the K nearest neighbors to current test example\n",
    "\t\t\t\n",
    "\tdef find_neighbors( self, x ) :\n",
    "\t\t\n",
    "\t\t# calculate all the euclidean distances between current\n",
    "\t\t# test example x and training set X_train\n",
    "\t\t\n",
    "\t\teuclidean_distances = np.zeros( self.m )\n",
    "\t\t\n",
    "\t\tfor i in range( self.m ) :\n",
    "\t\t\t\n",
    "\t\t\td = self.euclidean( x, self.X_train[i] )\n",
    "\t\t\t\n",
    "\t\t\teuclidean_distances[i] = d\n",
    "\t\t\n",
    "\t\t# sort Y_train according to euclidean_distance_array and\n",
    "\t\t# store into Y_train_sorted\n",
    "\t\t\n",
    "\t\tinds = euclidean_distances.argsort()\n",
    "\t\t\n",
    "\t\tY_train_sorted = self.Y_train[inds]\n",
    "\t\t\n",
    "\t\treturn Y_train_sorted[:self.K]\n",
    "\t\n",
    "\t# Function to calculate euclidean distance\n",
    "\t\t\t\n",
    "\tdef euclidean( self, x, x_train ) :\n",
    "\t\t\n",
    "\t\treturn np.sqrt( np.sum( np.square( x - x_train ) ) )\n",
    "\n",
    "\n",
    "\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "44eb0ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Driver code\n",
    "\n",
    "def main() :\n",
    "\t\n",
    "\t# Importing dataset\n",
    "\t\n",
    "\tdf = pd.read_csv( \"diabetes.csv\" )\n",
    "\n",
    "\tX = df.iloc[:,:-1].values\n",
    "\n",
    "\tY = df.iloc[:,-1:].values\n",
    "\t\n",
    "\t# Splitting dataset into train and test set\n",
    "\n",
    "\tX_train, X_test, Y_train, Y_test = train_test_split(\n",
    "\tX, Y, test_size = 1/3, random_state = 0 )\n",
    "\t\n",
    "\t# Model training\n",
    "\t\n",
    "\tmodel = K_Nearest_Neighbors_Classifier( K = 3 )\n",
    "\t\n",
    "\tmodel.fit( X_train, Y_train )\n",
    "\t\n",
    "\tmodel1 = KNeighborsClassifier( n_neighbors = 3 )\n",
    "\t\n",
    "\tmodel1.fit( X_train, Y_train )\n",
    "\t\n",
    "\t# Prediction on test set\n",
    "\n",
    "\tY_pred = model.predict( X_test )\n",
    "\t\n",
    "\tY_pred1 = model1.predict( X_test )\n",
    "\t\n",
    "\t# measure performance\n",
    "\t\n",
    "\tcorrectly_classified = 0\n",
    "\t\n",
    "\tcorrectly_classified1 = 0\n",
    "\t\n",
    "\t# counter\n",
    "\t\n",
    "\tcount = 0\n",
    "\t\n",
    "\tfor count in range( np.size( Y_pred ) ) :\n",
    "\t\t\n",
    "\t\tif Y_test[count] == Y_pred[count] :\n",
    "\t\t\t\n",
    "\t\t\tcorrectly_classified = correctly_classified + 1\n",
    "\t\t\n",
    "\t\tif Y_test[count] == Y_pred1[count] :\n",
    "\t\t\t\n",
    "\t\t\tcorrectly_classified1 = correctly_classified1 + 1\n",
    "\t\t\t\n",
    "\t\tcount = count + 1\n",
    "\t\t\n",
    "\tprint(\"Accuracy on test set by our model\t : \",(correctly_classified / count ) * 100 )\n",
    "\tprint(\"Accuracy on test set by sklearn model : \",(correctly_classified1 / count ) * 100 )\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be4754b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set by our model\t :  63.888888888888886\n",
      "Accuracy on test set by sklearn model :  63.888888888888886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acr00/vir_env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/tmp/ipykernel_3299/1818940012.py:47: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  Y_predict[i] = mode( neighbors )[0][0]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\" : \n",
    "      \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4890c8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49ef47e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29d62a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K Nearest Neighbors Regression\n",
    "\n",
    "class K_Nearest_Neighbors_Regressor() :\n",
    "\t\n",
    "\tdef __init__( self, K ) :\n",
    "\t\t\n",
    "\t\tself.K = K\n",
    "\t\t\n",
    "\t# Function to store training set\n",
    "\t\t\n",
    "\tdef fit( self, X_train, Y_train ) :\n",
    "\t\t\n",
    "\t\tself.X_train = X_train\n",
    "\t\t\n",
    "\t\tself.Y_train = Y_train\n",
    "\t\t\n",
    "\t\t# no_of_training_examples, no_of_features\n",
    "\t\t\n",
    "\t\tself.m, self.n = X_train.shape\n",
    "\t\n",
    "\t# Function for prediction\n",
    "\t\t\n",
    "\tdef predict( self, X_test ) :\n",
    "\t\t\n",
    "\t\tself.X_test = X_test\n",
    "\t\t\n",
    "\t\t# no_of_test_examples, no_of_features\n",
    "\t\t\n",
    "\t\tself.m_test, self.n = X_test.shape\n",
    "\t\t\n",
    "\t\t# initialize Y_predict\n",
    "\t\t\n",
    "\t\tY_predict = np.zeros( self.m_test )\n",
    "\t\t\n",
    "\t\tfor i in range( self.m_test ) :\n",
    "\t\t\t\n",
    "\t\t\tx = self.X_test[i]\n",
    "\t\t\t\n",
    "\t\t\t# find the K nearest neighbors from current test example\n",
    "\t\t\t\n",
    "\t\t\tneighbors = np.zeros( self.K )\n",
    "\t\t\t\n",
    "\t\t\tneighbors = self.find_neighbors( x )\n",
    "\t\t\t\n",
    "\t\t\t# calculate the mean of K nearest neighbors\n",
    "\t\t\t\n",
    "\t\t\tY_predict[i] = np.mean( neighbors )\n",
    "\t\t\t\n",
    "\t\treturn Y_predict\n",
    "\t\n",
    "\t# Function to find the K nearest neighbors to current test example\n",
    "\t\t\t\n",
    "\tdef find_neighbors( self, x ) :\n",
    "\t\t\n",
    "\t\t# calculate all the euclidean distances between current test\n",
    "\t\t# example x and training set X_train\n",
    "\t\t\n",
    "\t\teuclidean_distances = np.zeros( self.m )\n",
    "\t\t\n",
    "\t\tfor i in range( self.m ) :\n",
    "\t\t\t\n",
    "\t\t\td = self.euclidean( x, self.X_train[i] )\n",
    "\t\t\t\n",
    "\t\t\teuclidean_distances[i] = d\n",
    "\t\t\n",
    "\t\t# sort Y_train according to euclidean_distance_array and\n",
    "\t\t# store into Y_train_sorted\n",
    "\t\t\n",
    "\t\tinds = euclidean_distances.argsort()\n",
    "\t\t\n",
    "\t\tY_train_sorted = self.Y_train[inds]\n",
    "\t\t\n",
    "\t\treturn Y_train_sorted[:self.K]\n",
    "\t\n",
    "\t# Function to calculate euclidean distance\n",
    "\t\t\t\n",
    "\tdef euclidean( self, x, x_train ) :\n",
    "\t\t\n",
    "\t\treturn np.sqrt( np.sum( np.square( x - x_train ) ) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6863176e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Driver code\n",
    "\n",
    "def main() :\n",
    "\t\n",
    "\t# Importing dataset\n",
    "\t\n",
    "\tdf = pd.read_csv( \"salary_data.csv\" )\n",
    "\n",
    "\tX = df.iloc[:,:-1].values\n",
    "\n",
    "\tY = df.iloc[:,1].values\n",
    "\t\n",
    "\t# Splitting dataset into train and test set\n",
    "\n",
    "\tX_train, X_test, Y_train, Y_test = train_test_split(\n",
    "\tX, Y, test_size = 1/3, random_state = 0 )\n",
    "\t\n",
    "\t# Model training\n",
    "\t\n",
    "\tmodel = K_Nearest_Neighbors_Regressor( K = 3 )\n",
    "\n",
    "\tmodel.fit( X_train, Y_train )\n",
    "\t\n",
    "\tmodel1 = KNeighborsRegressor( n_neighbors = 3 )\n",
    "\t\n",
    "\tmodel1.fit( X_train, Y_train )\n",
    "\t\n",
    "\t# Prediction on test set\n",
    "\n",
    "\tY_pred = model.predict( X_test )\n",
    "\t\n",
    "\tY_pred1 = model1.predict( X_test )\n",
    "\t\n",
    "\tprint( \"Predicted values by our model\t : \", np.round( Y_pred[:3], 2 ) )\n",
    "\t\n",
    "\tprint( \"Predicted values by sklearn model : \", np.round( Y_pred1[:3], 2 ) )\n",
    "\t\n",
    "\tprint( \"Real values\t\t\t\t\t : \", Y_test[:3] )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "52be8ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values by our model\t :  [ 43024.33 113755.33  58419.  ]\n",
      "Predicted values by sklearn model :  [ 43024.33 113755.33  58419.  ]\n",
      "Real values\t\t\t\t\t :  [ 37731 122391  57081]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\" :\n",
    "\t\n",
    "\tmain()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
