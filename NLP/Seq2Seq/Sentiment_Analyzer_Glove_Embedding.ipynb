{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kxh-zpkv04CG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQz322In2R4i",
        "outputId": "ac023494-f0dc-4fc1-cd14-85fd1ddaa8cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path=\"/content/drive/MyDrive/NLP/glove.6B.100d.txt\""
      ],
      "metadata": {
        "id": "Q4_rm_qbNsCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def read_glove_vecs(path):\n",
        "  words = set()\n",
        "  word_to_vec_map = {}\n",
        "  with open(path,'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "      values = line.split()\n",
        "      word = values[0]\n",
        "      coefs = np.asarray(values[1:], dtype='float32')\n",
        "      words.add(word)\n",
        "      word_to_vec_map[word] = coefs\n",
        "\n",
        "  i = 1\n",
        "  words_to_index = {}\n",
        "  index_to_words = {}\n",
        "  for word in words:\n",
        "    words_to_index[word] = i\n",
        "    index_to_words[i] = word\n",
        "\n",
        "  return words,word_to_vec_map,words_to_index, index_to_words,\n",
        "\n",
        "words, word_to_vec_map,word_to_index, index_to_word = read_glove_vecs(path)"
      ],
      "metadata": {
        "id": "o0DVJ0Nm056d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define sentences_to_indices function\n",
        "def sentences_to_indices(X, word_to_index, max_len):\n",
        "    m = len(X)\n",
        "    X_indices = np.zeros((m, max_len))\n",
        "    for i in range(m):\n",
        "        sentence_words = X[i].lower().split()\n",
        "        j = 0\n",
        "        for w in sentence_words:\n",
        "            if w in word_to_index:\n",
        "                X_indices[i, j] = word_to_index[w]\n",
        "                j += 1\n",
        "    return X_indices\n"
      ],
      "metadata": {
        "id": "Duhvnau83F-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "736D6MBX6pJX",
        "outputId": "58ad30cd-78d2-409a-b78a-818ee75fb519"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "LTuUxyUv-Mcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading data\n",
        "df = pd.read_csv('/content/drive/MyDrive/NLP/train_emoji.csv')\n",
        "X_train, Y_train = df.iloc[:,0].values, df.iloc[:,1].values\n",
        "\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/NLP/tesss.csv')\n",
        "X_test, Y_test = df.iloc[:,0].values, df.iloc[:,1].values\n",
        "\n",
        "\n",
        "# Preprocessing\n",
        "maxLen = len(max(X_train, key=len).split())\n",
        "print(f\"maxLen : {maxLen}\")\n",
        "\n",
        "X_train_indices = torch.from_numpy(sentences_to_indices(X_train, word_to_index, maxLen)).long()\n",
        "Y_train_oh = torch.from_numpy(np.eye(5)[Y_train.reshape(-1)]).float()  # 5 classes, 1D array\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkq0tXi4-Mie",
        "outputId": "7aa5c04b-c885-40ba-a1e1-d98b337e3d59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "maxLen : 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Embedding layer\n",
        "class EmbeddingLayer(nn.Module):\n",
        "    def __init__(self, word_to_vec_map, word_to_index):\n",
        "        super(EmbeddingLayer, self).__init__()\n",
        "        vocab_size = len(word_to_index) + 1\n",
        "        any_word = list(word_to_vec_map.keys())[0]\n",
        "        emb_dim = word_to_vec_map[any_word].shape[0]\n",
        "\n",
        "        emb_matrix = np.zeros((vocab_size, emb_dim))\n",
        "        for word, idx in word_to_index.items():\n",
        "            emb_matrix[idx, :] = word_to_vec_map[word]\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.embedding.weight.data.copy_(torch.from_numpy(emb_matrix))\n",
        "        self.embedding.weight.requires_grad = False\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        return self.embedding(inputs)\n"
      ],
      "metadata": {
        "id": "WIlnTRDv-MkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Emojify(nn.Module):\n",
        "    def __init__(self, input_size, embedding_layer):\n",
        "        super(Emojify, self).__init__()\n",
        "        self.embedding = embedding_layer\n",
        "        self.lstm1 = nn.LSTM(input_size, 128, batch_first=True, bidirectional=True)\n",
        "        self.dropout1 = nn.Dropout(0.5)\n",
        "        self.lstm2 = nn.LSTM(256, 128, batch_first=True, bidirectional=True)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.lstm3 = nn.LSTM(256, 128, batch_first=True)\n",
        "        self.dropout3 = nn.Dropout(0.5)\n",
        "        self.fc = nn.Linear(128, 5) # output has 5 classes C=5\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embeddings = self.embedding(inputs)\n",
        "        output, _ = self.lstm1(embeddings)\n",
        "        output = self.dropout1(output)\n",
        "        output, _ = self.lstm2(output)\n",
        "        output = self.dropout2(output)\n",
        "        output, (hidden, _) = self.lstm3(output)\n",
        "        output = self.dropout3(hidden.squeeze(0))\n",
        "        output = self.fc(output)\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "FiRWAtvx-jOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate model\n",
        "input_size = word_to_vec_map[list(word_to_vec_map.keys())[0]].shape[0]\n",
        "embedding_layer = EmbeddingLayer(word_to_vec_map, word_to_index)\n",
        "model = Emojify(input_size,embedding_layer)\n",
        "\n",
        "# Model Details\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuOD1ylc-jVJ",
        "outputId": "840d7b25-51df-48a2-de32-f7f6204eac43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Emojify(\n",
            "  (embedding): EmbeddingLayer(\n",
            "    (embedding): Embedding(400001, 100)\n",
            "  )\n",
            "  (lstm1): LSTM(100, 128, batch_first=True, bidirectional=True)\n",
            "  (dropout1): Dropout(p=0.5, inplace=False)\n",
            "  (lstm2): LSTM(256, 128, batch_first=True, bidirectional=True)\n",
            "  (dropout2): Dropout(p=0.5, inplace=False)\n",
            "  (lstm3): LSTM(256, 128, batch_first=True)\n",
            "  (dropout3): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=128, out_features=5, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "for epoch in range(50):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train_indices)\n",
        "    loss = criterion(outputs, Y_train_oh.argmax(dim=1))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/50], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "id": "WnHz18p1O6OB",
        "outputId": "aeb72555-9f02-4215-e4f3-e48c88deb535",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/50], Loss: 1.5570\n",
            "Epoch [20/50], Loss: 1.5641\n",
            "Epoch [30/50], Loss: 1.5391\n",
            "Epoch [40/50], Loss: 1.5045\n",
            "Epoch [50/50], Loss: 1.4997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Testing\n",
        "X_test_indices = torch.from_numpy(sentences_to_indices(X_test, word_to_index, maxLen)).long()\n",
        "Y_test_oh = torch.from_numpy(np.eye(5)[Y_test.reshape(-1)]).float()\n",
        "Y_test_tensor = torch.from_numpy(Y_test)  # Convert Y_test to a PyTorch Tensor\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_test_indices)\n",
        "    loss = criterion(outputs, Y_test_oh.argmax(dim=1))\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total = Y_test_tensor.size(0)  # Use Y_test_tensor instead of Y_test\n",
        "    correct = (predicted == Y_test_oh.argmax(dim=1)).sum().item()\n",
        "    acc = correct / total\n",
        "\n",
        "print(f'Test Accuracy: {acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZA3mZYI-3fj",
        "outputId": "8682edac-df47-445b-b7e0-25ed45d32eb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.2545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q emoji"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PB9Ui6pC0-_8",
        "outputId": "325a13f6-e623-44a1-f8bd-f60007d96f6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/433.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.6/433.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m430.1/433.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.8/433.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import emoji\n",
        "\n",
        "emoji_dictionary = {#\"0\": \":red_heart:\",    # :heart: prints a black instead of red heart depending on the font\n",
        "                    \"0\": \"\\u2764\\ufe0f\",\n",
        "                    \"1\": \":baseball:\",\n",
        "                    \"2\": \":smile:\",\n",
        "                    \"3\": \":disappointed:\",\n",
        "                    \"4\": \":fork_and_knife:\"}\n",
        "\n",
        "def label_to_emoji(label):\n",
        "    \"\"\"\n",
        "    Converts a label (int or string) into the corresponding emoji code (string) ready to be printed\n",
        "    \"\"\"\n",
        "    return emoji.emojize(emoji_dictionary[str(label)])"
      ],
      "metadata": {
        "id": "V8P7hse7v5C7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "C = 5\n",
        "y_test_oh = torch.from_numpy(np.eye(C)[Y_test.reshape(-1)]).float()\n",
        "\n",
        "X_test_indices = torch.from_numpy(sentences_to_indices(X_test, word_to_index, maxLen)).long()\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    pred = model(X_test_indices)\n",
        "    _, predicted = torch.max(pred.data, 1)\n",
        "\n",
        "\n",
        "for i in range(len(X_test)):\n",
        "    if predicted[i] != Y_test[i]:\n",
        "        print('Expected emoji: ' + label_to_emoji(Y_test[i]) + ' prediction: ' + X_test[i] + label_to_emoji(predicted[i].item()).strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlH8NWnV-3nT",
        "outputId": "9f1cf0f9-67b1-42f6-e0e6-3efb42a1e867"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected emoji: :smile: prediction: he got a very nice raise\t:disappointed:\n",
            "Expected emoji: :smile: prediction: she got me a nice present\t:disappointed:\n",
            "Expected emoji: :smile: prediction: ha ha ha it was so funny\t:disappointed:\n",
            "Expected emoji: :smile: prediction: he is a good friend\t:disappointed:\n",
            "Expected emoji: :disappointed: prediction: I am upset\t:smile:\n",
            "Expected emoji: :smile: prediction: We had such a lovely dinner tonight\t:disappointed:\n",
            "Expected emoji: 🍴 prediction: where is the food\t:disappointed:\n",
            "Expected emoji: :smile: prediction: Stop making this joke ha ha ha\t:disappointed:\n",
            "Expected emoji: ⚾ prediction: where is the ball\t:disappointed:\n",
            "Expected emoji: :disappointed: prediction: work is hard\t:smile:\n",
            "Expected emoji: :disappointed: prediction: are you serious:smile:\n",
            "Expected emoji: ⚾ prediction: Let us go play baseball\t:disappointed:\n",
            "Expected emoji: :disappointed: prediction: work is horrible\t:smile:\n",
            "Expected emoji: :smile: prediction: Congratulation for having a baby\t:disappointed:\n",
            "Expected emoji: 🍴 prediction: any suggestions for dinner\t:disappointed:\n",
            "Expected emoji: ❤️ prediction: I love taking breaks\t:disappointed:\n",
            "Expected emoji: :smile: prediction: you brighten my day\t:disappointed:\n",
            "Expected emoji: 🍴 prediction: I boiled rice\t:smile:\n",
            "Expected emoji: :disappointed: prediction: I am upset\t:smile:\n",
            "Expected emoji: ⚾ prediction: give me the ball:disappointed:\n",
            "Expected emoji: ❤️ prediction: My grandmother is the love of my life\t:disappointed:\n",
            "Expected emoji: ⚾ prediction: enjoy your game:smile:\n",
            "Expected emoji: :smile: prediction: valentine day is near\t:disappointed:\n",
            "Expected emoji: ❤️ prediction: I miss you so much\t:disappointed:\n",
            "Expected emoji: ⚾ prediction: throw the ball\t:smile:\n",
            "Expected emoji: :smile: prediction: will you be my valentine\t:disappointed:\n",
            "Expected emoji: ⚾ prediction: he can pitch really well\t:disappointed:\n",
            "Expected emoji: 🍴 prediction: I am hungry:smile:\n",
            "Expected emoji: 🍴 prediction: See you at the restaurant\t:disappointed:\n",
            "Expected emoji: :smile: prediction: I like to laugh\t:disappointed:\n",
            "Expected emoji: ⚾ prediction: I will  run:smile:\n",
            "Expected emoji: ❤️ prediction: I like your jacket \t:disappointed:\n",
            "Expected emoji: ❤️ prediction: i miss her\t:smile:\n",
            "Expected emoji: ⚾ prediction: what is your favorite baseball game\t:disappointed:\n",
            "Expected emoji: ❤️ prediction: I love you to the stars and back\t:disappointed:\n",
            "Expected emoji: :smile: prediction: What you did was awesome\t:disappointed:\n",
            "Expected emoji: :smile: prediction: ha ha ha lol\t:disappointed:\n",
            "Expected emoji: :disappointed: prediction: go away\t:smile:\n",
            "Expected emoji: ❤️ prediction: family is all I have\t:disappointed:\n",
            "Expected emoji: :smile: prediction: You deserve this nice prize\t:disappointed:\n",
            "Expected emoji: 🍴 prediction: I did not have breakfast :disappointed:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction\n",
        "x_test = np.array(['I cannot play'])\n",
        "X_test_indices = torch.from_numpy(sentences_to_indices(x_test, word_to_index, maxLen)).long()\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model(X_test_indices)\n",
        "    _, predicted = torch.max(output.data, 1)\n",
        "    print(x_test[0] + ' ' + label_to_emoji(predicted.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXgJHz0I_E_T",
        "outputId": "60fadc75-c868-4481-8297-454ed209cb9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I cannot play :smile:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "7oI_5ovT6pQK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}