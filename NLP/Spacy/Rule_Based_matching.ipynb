{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4fc9a3c-609e-47e2-a669-d0d4946a0190",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acro0/NLP/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline: ['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from spacy import displacy\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "print(\"Pipeline:\", nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b2ad91-43bf-4364-b514-6d73f9af3f11",
   "metadata": {},
   "source": [
    "# Token-based matching\n",
    "\n",
    "spaCy features a rule-matching engine, the Matcher, that operates over tokens, similar to regular expressions. The rules can refer to token annotations (e.g. the token text or tag_, and flags like IS_PUNCT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7587ed4-2e46-4d57-acf7-c86ea0286623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barack Obama PERSON\n",
      "Barack Obama PERSON\n"
     ]
    }
   ],
   "source": [
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import Span\n",
    "\n",
    "nlp_e = spacy.blank(\"en\")\n",
    "matcher = Matcher(nlp_e.vocab)\n",
    "matcher.add(\"PERSON\", [[{\"lower\": \"barack\"}, {\"lower\": \"obama\"}]])\n",
    "doc = nlp_e(\"Barack Obama was the 44th president of the United States\")\n",
    "\n",
    "# 1. Return (match_id, start, end) tuples\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    # Create the matched span and assign the match_id as a label\n",
    "    span = Span(doc, start, end, label=match_id)\n",
    "    print(span.text, span.label_)\n",
    "\n",
    "# 2. Return Span objects directly\n",
    "matches = matcher(doc, as_spans=True)\n",
    "for span in matches:\n",
    "    print(span.text, span.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "823cec02-b6e6-4989-993e-7097e495b295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found match: United States\n",
      "Found match: United States\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "doc = nlp(\"\"\"The United States of America (USA) are commonly \n",
    "            known as the United States (U.S. or US) or America.\"\"\")\n",
    "\n",
    "expression = r\"[Uu](nited|\\\\.?) ?[Ss](tates|\\\\.?)\"\n",
    "\n",
    "for match in re.finditer(expression, doc.text):\n",
    "    start, end = match.span()\n",
    "    span = doc.char_span(start, end)\n",
    "    # This is a Span object or None if match doesn't map to valid token sequence\n",
    "    if span is not None:\n",
    "        print(\"Found match:\", span.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdaa8ad-9377-4d80-9636-c01d66532afb",
   "metadata": {},
   "source": [
    "# Efficient phrase matching\n",
    "\n",
    "If you need to match large terminology lists, you can also use the PhraseMatcher and create Doc objects instead of token patterns, which is much more efficient overall. The Doc patterns can contain single or multiple tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46c218c5-f9cb-44d2-b265-ed34c08da659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angela Merkel\n",
      "Barack Obama\n",
      "Washington, D.C.\n"
     ]
    }
   ],
   "source": [
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "terms = [\"Barack Obama\", \"Angela Merkel\", \"Washington, D.C.\"]\n",
    "# Only run nlp.make_doc to speed things up\n",
    "patterns = [nlp.make_doc(text) for text in terms]\n",
    "matcher.add(\"TerminologyList\", patterns)\n",
    "\n",
    "doc = nlp(\"German Chancellor Angela Merkel and US President Barack Obama \"\n",
    "          \"converse in the Oval Office inside the White House in Washington, D.C.\")\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    span = doc[start:end]\n",
    "    print(span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fdded46-697a-4658-b287-349fac8b4ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched based on token shape: 192.168.1.1\n",
      "Matched based on token shape: 192.168.2.1\n"
     ]
    }
   ],
   "source": [
    "from spacy.lang.en import English\n",
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "nlp_e = English()\n",
    "matcher = PhraseMatcher(nlp_e.vocab, attr=\"SHAPE\")\n",
    "matcher.add(\"IP\", [nlp_e(\"127.0.0.1\"), nlp_e(\"127.127.0.0\")])\n",
    "\n",
    "doc = nlp_e(\"Often the router will have an IP address such as 192.168.1.1 or 192.168.2.1.\")\n",
    "for match_id, start, end in matcher(doc):\n",
    "    print(\"Matched based on token shape:\", doc[start:end])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdaf5330-8456-4005-bdf9-eca1ee479f2b",
   "metadata": {},
   "source": [
    "# Dependency Matcher\n",
    "\n",
    "The DependencyMatcher lets you match patterns within the dependency parse using Semgrex operators. It requires a model containing a parser such as the DependencyParser. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "668bcf6d-7999-483e-8c09-060b019c25bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4851363122962674176, [7, 0, 10, 9])]\n",
      "anchor_founded: founded\n",
      "founded_subject: Lee\n",
      "founded_object: startups\n",
      "founded_object_modifier: AI\n"
     ]
    }
   ],
   "source": [
    "from spacy.matcher import DependencyMatcher\n",
    "\n",
    "matcher = DependencyMatcher(nlp.vocab)\n",
    "pattern = [\n",
    "    {\n",
    "        \"RIGHT_ID\": \"anchor_founded\",\n",
    "        \"RIGHT_ATTRS\": {\"ORTH\": \"founded\"}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"anchor_founded\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"founded_subject\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"nsubj\"},\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"anchor_founded\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"founded_object\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"dobj\"},\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"founded_object\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"founded_object_modifier\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": {\"IN\": [\"amod\", \"compound\"]}},\n",
    "    }\n",
    "]\n",
    "\n",
    "matcher.add(\"FOUNDED\", [pattern])\n",
    "doc = nlp(\"Lee, an experienced CEO, has founded two AI startups.\")\n",
    "matches = matcher(doc)\n",
    "\n",
    "print(matches) # [(4851363122962674176, [6, 0, 10, 9])]\n",
    "# Each token_id corresponds to one pattern dict\n",
    "match_id, token_ids = matches[0]\n",
    "for i in range(len(token_ids)):\n",
    "    print(pattern[i][\"RIGHT_ID\"] + \":\", doc[token_ids[i]].text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91898aee-e1fe-4709-b73c-2934ac2448cd",
   "metadata": {},
   "source": [
    "# Rule-based entity recognition\n",
    "\n",
    "The EntityRuler is a component that lets you add named entities based on pattern dictionaries, which makes it easy to combine rule-based and statistical named entity recognition for even more powerful pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ecc0da9-3672-4e19-92bf-bb8e38f1a045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc1</th>\n",
       "      <th>Doc2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Apple, ORG, apple]</td>\n",
       "      <td>[Apple, ORG, apple]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[San Francisco, GPE, san-francisco]</td>\n",
       "      <td>[San Fran, GPE, san-francisco]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Doc1                            Doc2\n",
       "0                  [Apple, ORG, apple]             [Apple, ORG, apple]\n",
       "1  [San Francisco, GPE, san-francisco]  [San Fran, GPE, san-francisco]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "nlp_e = English()\n",
    "ruler = nlp_e.add_pipe(\"entity_ruler\")\n",
    "patterns = [{\"label\": \"ORG\", \"pattern\": \"Apple\", \"id\": \"apple\"},\n",
    "            {\"label\": \"GPE\", \"pattern\": [{\"LOWER\": \"san\"}, {\"LOWER\": \"francisco\"}], \"id\": \"san-francisco\"},\n",
    "            {\"label\": \"GPE\", \"pattern\": [{\"LOWER\": \"san\"}, {\"LOWER\": \"fran\"}], \"id\": \"san-francisco\"}]\n",
    "ruler.add_patterns(patterns)\n",
    "\n",
    "data1 = []\n",
    "doc1 = nlp_e(\"Apple is opening its first big office in San Francisco.\")\n",
    "for ent in doc1.ents:\n",
    "    data1.append([ent.text, ent.label_, ent.ent_id_])\n",
    "\n",
    "data2 = []\n",
    "doc2 = nlp_e(\"Apple is opening its first big office in San Fran.\")\n",
    "for ent in doc2.ents:\n",
    "    data2.append([ent.text, ent.label_, ent.ent_id_])\n",
    "\n",
    "df = pd.DataFrame({\"Doc1\":data1,\"Doc2\":data2})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac4ead6-edc4-4e5f-8f0f-887bbddf52c5",
   "metadata": {},
   "source": [
    "# Rule-based span matching\n",
    "\n",
    "The SpanRuler is a generalized version of the entity ruler that lets you add spans to doc.spans or doc.ents based on pattern dictionaries, which makes it easy to combine rule-based and statistical pipeline components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46399719-33e0-405d-93e9-c96742cfa4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('MyCorp Inc.', 'ORG'), ('U.S.', 'GPE')]\n"
     ]
    }
   ],
   "source": [
    "config = {\"spans_key\": None, \"annotate_ents\": True, \"overwrite\": False}\n",
    "ruler = nlp.add_pipe(\"span_ruler\", config=config)\n",
    "patterns = [{\"label\": \"ORG\", \"pattern\": \"MyCorp Inc.\"}]\n",
    "ruler.add_patterns(patterns)\n",
    "\n",
    "doc = nlp(\"MyCorp Inc. is a company in the U.S.\")\n",
    "print([(ent.text, ent.label_) for ent in doc.ents])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67dbf80f-24ff-4c0b-a480-3a6b1c321bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
